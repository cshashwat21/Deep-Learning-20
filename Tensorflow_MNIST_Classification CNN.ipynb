{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VujHXPz2dkm"
   },
   "source": [
    "## MNIST Handwriting Classifcation\n",
    "\n",
    "The MNIST dataset comprises 60,000 training examples and 10,000 test examples of the handwritten digits 0–9, formatted as 28x28-pixel monochrome images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "tC6QGpB-jkgO",
    "outputId": "37365a44-fcb2-437a-d2a2-3149036c6899"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZ0YRn8O3EdK"
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "Convolutional neural networks (CNNs) are the current state-of-the-art model architecture for image classification tasks. CNNs apply a series of filters to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. CNNs contains three components:\n",
    "\n",
    "**Convolutional layers**, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. Convolutional layers then typically apply a ReLU activation function to the output to introduce nonlinearities into the model.\n",
    "\n",
    "**Pooling layers**, which downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is max pooling, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values.\n",
    "\n",
    "**Dense** (fully connected) layers, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
    "\n",
    "Typically, a CNN is composed of a stack of convolutional modules that perform feature extraction. Each module consists of a convolutional layer followed by a pooling layer. The last convolutional module is followed by one or more dense layers that perform classification. The final dense layer in a CNN contains a single node for each target class in the model (all the possible classes the model may predict), with a softmax activation function to generate a value between 0–1 for each node (the sum of all these softmax values is equal to 1). We can interpret the softmax values for a given image as relative measurements of how likely it is that the image falls into each target class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04qjsx6t3Set"
   },
   "source": [
    "## Building the CNN MNIST Classifier\n",
    "\n",
    "Let's build a model to classify the images in the MNIST dataset using the\n",
    "following CNN architecture:\n",
    "\n",
    "1.  **Convolutional Layer #1**: Applies 32 5x5 filters (extracting 5x5-pixel\n",
    "    subregions), with ReLU activation function\n",
    "2.  **Pooling Layer #1**: Performs max pooling with a 2x2 filter and stride of 2\n",
    "    (which specifies that pooled regions do not overlap)\n",
    "3.  **Convolutional Layer #2**: Applies 64 5x5 filters, with ReLU activation\n",
    "    function\n",
    "4.  **Pooling Layer #2**: Again, performs max pooling with a 2x2 filter and\n",
    "    stride of 2\n",
    "5.  **Dense Layer #1**: 1,024 neurons, with dropout regularization rate of 0.4\n",
    "    (probability of 0.4 that any given element will be dropped during training)\n",
    "6.  **Dense Layer #2 (Logits Layer)**: 10 neurons, one for each digit target\n",
    "    class (0–9).\n",
    "\n",
    "The `tf.layers` module contains methods to create each of the three layer types\n",
    "above:\n",
    "\n",
    "*   `conv2d()`. Constructs a two-dimensional convolutional layer. Takes number\n",
    "    of filters, filter kernel size, padding, and activation function as\n",
    "    arguments.\n",
    "*   `max_pooling2d()`. Constructs a two-dimensional pooling layer using the\n",
    "    max-pooling algorithm. Takes pooling filter size and stride as arguments.\n",
    "*   `dense()`. Constructs a dense layer. Takes number of neurons and activation\n",
    "    function as arguments.\n",
    "\n",
    "Each of these methods accepts a tensor as input and returns a transformed tensor\n",
    "as output. This makes it easy to connect one layer to another: just take the\n",
    "output from one layer-creation method and supply it as input to another.\n",
    "\n",
    "Add the following `cnn_model_fn` function, which\n",
    "conforms to the interface expected by TensorFlow's Estimator API. This function takes\n",
    "MNIST feature data, labels, and mode (from\n",
    "`tf.estimator.ModeKeys`: `TRAIN`, `EVAL`, `PREDICT`) as arguments;\n",
    "configures the CNN; and returns predictions, loss, and a training operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MD4fKtS3opk"
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0s5QAVn4bR1"
   },
   "source": [
    "### Input Layer\n",
    "The methods in the layers module for creating convolutional and pooling layers for two-dimensional image data expect input tensors to have a shape of [batch_size, image_height, image_width, channels] by default. This behavior can be changed using the data_format parameter; defined as follows:\n",
    "\n",
    "batch_size —Size of the subset of examples to use when performing gradient descent during training.\n",
    "image_height —Height of the example images.\n",
    "image_width —Width of the example images.\n",
    "channels —Number of color channels in the example images. For color images, the number of channels is 3 (red, green, blue). For monochrome images, there is just 1 channel (black).\n",
    "data_format —A string, one of channels_last (default) or channels_first. channels_last corresponds to inputs with shape (batch, ..., channels) while channels_first corresponds to inputs with shape (batch, channels, ...).\n",
    "Here, our MNIST dataset is composed of monochrome 28x28 pixel images, so the desired shape for our input layer is [batch_size, 28, 28, 1].\n",
    "\n",
    "To convert our input feature map (features) to this shape, we can perform the following reshape operation:\n",
    "\n",
    "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "Note that we've indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features[\"x\"], holding the size of all other dimensions constant. This allows us to treat batch_size as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, features[\"x\"] will contain 3,920 values (one value for each pixel in each image), and input_layer will have a shape of [5, 28, 28, 1]. Similarly, if we feed examples in batches of 100, features[\"x\"] will contain 78,400 values, and input_layer will have a shape of [100, 28, 28, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZJu1P1s4hzN"
   },
   "source": [
    "### Convolutional Layer #1\n",
    "\n",
    "In our first convolutional layer, we want to apply 32 5x5 filters to the input\n",
    "layer, with a ReLU activation function. We can use the `conv2d()` method in the\n",
    "`layers` module to create this layer as follows:\n",
    "\n",
    "```\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "```\n",
    "\n",
    "The `inputs` argument specifies our input tensor, which must have the shape\n",
    "<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n",
    "<em>channels</em>]</code>. Here, we're connecting our first convolutional layer\n",
    "to `input_layer`, which has the shape <code>[<em>batch_size</em>, 28, 28,\n",
    "1]</code>.\n",
    "\n",
    "Note: `conv2d()` will instead accept a shape of `[batch_size, channels, image_height, image_width]` when passed the argument `data_format=channels_first`.\n",
    "\n",
    "The `filters` argument specifies the number of filters to apply (here, 32), and\n",
    "`kernel_size` specifies the dimensions of the filters as `[height,\n",
    "width].\n",
    "\n",
    "<p class=\"tip\"><b>TIP:</b> If filter height and width have the same value, you can instead specify a\n",
    "single integer for <code>kernel_size</code>—e.g., <code>kernel_size=5</code>.</p>\n",
    "\n",
    "The `padding` argument specifies one of two enumerated values\n",
    "(case-insensitive): `valid` (default value) or `same`. To specify that the\n",
    "output tensor should have the same height and width values as the input tensor,\n",
    "we set `padding=same` here, which instructs TensorFlow to add 0 values to the\n",
    "edges of the input tensor to preserve height and width of 28. (Without padding,\n",
    "a 5x5 convolution over a 28x28 tensor will produce a 24x24 tensor, as there are\n",
    "24x24 locations to extract a 5x5 tile from a 28x28 grid.)\n",
    "\n",
    "The `activation` argument specifies the activation function to apply to the\n",
    "output of the convolution. Here, we specify ReLU activation with\n",
    "`tf.nn.relu`.\n",
    "\n",
    "Our output tensor produced by `conv2d()` has a shape of\n",
    "<code>[<em>batch_size</em>, 28, 28, 32]</code>: the same height and width\n",
    "dimensions as the input, but now with 32 channels holding the output from each\n",
    "of the filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymbpq7J06P3I"
   },
   "source": [
    "### Pooling Layer #1\n",
    "\n",
    "Next, we connect our first pooling layer to the convolutional layer we just\n",
    "created. We can use the `max_pooling2d()` method in `layers` to construct a\n",
    "layer that performs max pooling with a 2x2 filter and stride of 2:\n",
    "\n",
    "```\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "```\n",
    "\n",
    "Again, `inputs` specifies the input tensor, with a shape of\n",
    "<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n",
    "<em>channels</em>]</code>. Here, our input tensor is `conv1`, the output from\n",
    "the first convolutional layer, which has a shape of <code>[<em>batch_size</em>,\n",
    "28, 28, 32]</code>.\n",
    "\n",
    "Note: As with <code>conv2d()</code>, <code>max_pooling2d()</code> will instead\n",
    "accept a shape of <code>[<em>batch_size</em>, <em>channels</em>,\n",
    "<em>image_height</em>, <em>image_width</em>]</code> when passed the argument\n",
    "<code>data_format=channels_first</code>.\n",
    "\n",
    "The `pool_size` argument specifies the size of the max pooling filter as\n",
    "<code>[<em>height</em>, <em>width</em>]</code> (here, `[2, 2]`). If both\n",
    "dimensions have the same value, you can instead specify a single integer (e.g.,\n",
    "`pool_size=2`).\n",
    "\n",
    "The `strides` argument specifies the size of the stride. Here, we set a stride\n",
    "of 2, which indicates that the subregions extracted by the filter should be\n",
    "separated by 2 pixels in both the height and width dimensions (for a 2x2 filter,\n",
    "this means that none of the regions extracted will overlap). If you want to set\n",
    "different stride values for height and width, you can instead specify a tuple or\n",
    "list (e.g., `stride=[3, 6]`).\n",
    "\n",
    "Our output tensor produced by `max_pooling2d()` (`pool1`) has a shape of\n",
    "<code>[<em>batch_size</em>, 14, 14, 32]</code>: the 2x2 filter reduces height and width by 50% each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8g97unz7AMi"
   },
   "source": [
    "### Convolutional Layer #2 and Pooling Layer #2\n",
    "\n",
    "We can connect a second convolutional and pooling layer to our CNN using\n",
    "`conv2d()` and `max_pooling2d()` as before. For convolutional layer #2, we\n",
    "configure 64 5x5 filters with ReLU activation, and for pooling layer #2, we use\n",
    "the same specs as pooling layer #1 (a 2x2 max pooling filter with stride of 2):\n",
    "\n",
    "```\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "```\n",
    "\n",
    "Note that convolutional layer #2 takes the output tensor of our first pooling\n",
    "layer (`pool1`) as input, and produces the tensor `conv2` as output. `conv2`\n",
    "has a shape of <code>[<em>batch_size</em>, 14, 14, 64]</code>, the same height and width as `pool1` (due to `padding=\"same\"`), and 64 channels for the 64\n",
    "filters applied.\n",
    "\n",
    "Pooling layer #2 takes `conv2` as input, producing `pool2` as output. `pool2`\n",
    "has shape <code>[<em>batch_size</em>, 7, 7, 64]</code> (50% reduction of height and width from `conv2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3wiQZ_j7-B0"
   },
   "source": [
    "### Dense Layer\n",
    "\n",
    "Next, we want to add a dense layer (with 1,024 neurons and ReLU activation) to\n",
    "our CNN to perform classification on the features extracted by the\n",
    "convolution/pooling layers. Before we connect the layer, however, we'll flatten\n",
    "our feature map (`pool2`) to shape <code>[<em>batch_size</em>,\n",
    "<em>features</em>]</code>, so that our tensor has only two dimensions:\n",
    "\n",
    "```\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "```\n",
    "\n",
    "In the `reshape()` operation above, the `-1` signifies that the *`batch_size`*\n",
    "dimension will be dynamically calculated based on the number of examples in our\n",
    "input data. Each example has 7 (`pool2` height) * 7 (`pool2` width) * 64\n",
    "(`pool2` channels) features, so we want the `features` dimension to have a value\n",
    "of 7 * 7 * 64 (3136 in total). The output tensor, `pool2_flat`, has shape\n",
    "<code>[<em>batch_size</em>, 3136]</code>.\n",
    "\n",
    "Now, we can use the `dense()` method in `layers` to connect our dense layer as\n",
    "follows:\n",
    "\n",
    "```\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "```\n",
    "\n",
    "The `inputs` argument specifies the input tensor: our flattened feature map,\n",
    "`pool2_flat`. The `units` argument specifies the number of neurons in the dense\n",
    "layer (1,024). The `activation` argument takes the activation function; again,\n",
    "we'll use `tf.nn.relu` to add ReLU activation.\n",
    "\n",
    "To help improve the results of our model, we also apply dropout regularization\n",
    "to our dense layer, using the `dropout` method in `layers`:\n",
    "\n",
    "```\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "```\n",
    "\n",
    "Again, `inputs` specifies the input tensor, which is the output tensor from our\n",
    "dense layer (`dense`).\n",
    "\n",
    "The `rate` argument specifies the dropout rate; here, we use `0.4`, which means\n",
    "40% of the elements will be randomly dropped out during training.\n",
    "\n",
    "The `training` argument takes a boolean specifying whether or not the model is\n",
    "currently being run in training mode; dropout will only be performed if\n",
    "`training` is `True`. Here, we check if the `mode` passed to our model function\n",
    "`cnn_model_fn` is `TRAIN` mode.\n",
    "\n",
    "Our output tensor `dropout` has shape <code>[<em>batch_size</em>, 1024]</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WuyOa_88GLJ"
   },
   "source": [
    "### Logits Layer\n",
    "\n",
    "The final layer in our neural network is the logits layer, which will return the\n",
    "raw values for our predictions. We create a dense layer with 10 neurons (one for\n",
    "each target class 0–9), with linear activation (the default):\n",
    "\n",
    "```\n",
    "logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "```\n",
    "\n",
    "Our final output tensor of the CNN, `logits`, has shape `[batch_size, 10]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eudhOXLL8HXK"
   },
   "source": [
    "### Generate Predictions {#generate_predictions}\n",
    "\n",
    "The logits layer of our model returns our predictions as raw values in a\n",
    "<code>[<em>batch_size</em>, 10]</code>-dimensional tensor. Let's convert these\n",
    "raw values into two different formats that our model function can return:\n",
    "\n",
    "*   The **predicted class** for each example: a digit from 0–9.\n",
    "*   The **probabilities** for each possible target class for each example: the\n",
    "    probability that the example is a 0, is a 1, is a 2, etc.\n",
    "\n",
    "For a given example, our predicted class is the element in the corresponding row\n",
    "of the logits tensor with the highest raw value. We can find the index of this\n",
    "element using the `tf.argmax`\n",
    "function:\n",
    "\n",
    "```\n",
    "tf.argmax(input=logits, axis=1)\n",
    "```\n",
    "\n",
    "The `input` argument specifies the tensor from which to extract maximum\n",
    "values—here `logits`. The `axis` argument specifies the axis of the `input`\n",
    "tensor along which to find the greatest value. Here, we want to find the largest\n",
    "value along the dimension with index of 1, which corresponds to our predictions\n",
    "(recall that our logits tensor has shape <code>[<em>batch_size</em>,\n",
    "10]</code>).\n",
    "\n",
    "We can derive probabilities from our logits layer by applying softmax activation\n",
    "using `tf.nn.softmax`:\n",
    "\n",
    "```\n",
    "tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "```\n",
    "\n",
    "\n",
    "We compile our predictions in a dict, and return an `EstimatorSpec` object:\n",
    "\n",
    "```\n",
    "predictions = {\n",
    "    \"classes\": tf.argmax(input=logits, axis=1),\n",
    "    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ASFk9ZxL4a5B",
    "outputId": "9e8296c6-09e4-4616-eec1-287b3d68f292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "id": "uKueUKi86Vba",
    "outputId": "4ee240f8-a993-4176-d412-ef7767f20a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f347f438518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SoIEk4Tp6gDI"
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvIypfp1Gdun"
   },
   "source": [
    "We store a dict of the tensors we want to log in `tensors_to_log`. Each key is a\n",
    "label of our choice that will be printed in the log output, and the\n",
    "corresponding label is the name of a `Tensor` in the TensorFlow graph. Here, our\n",
    "`probabilities` can be found in `softmax_tensor`, the name we gave our softmax\n",
    "operation earlier when we generated the probabilities in `cnn_model_fn`.\n",
    "\n",
    "Note: If you don't explicitly assign a name to an operation via the `name` argument, TensorFlow will assign a default name. A couple easy ways to discover the names applied to operations are to visualize your graph on [TensorBoard](../../guide/graph_viz.md)) or to enable the [TensorFlow Debugger (tfdbg)](../../guide/debugger.md).\n",
    "\n",
    "Next, we create the `LoggingTensorHook`, passing `tensors_to_log` to the\n",
    "`tensors` argument. We set `every_n_iter=50`, which specifies that probabilities\n",
    "should be logged after every 50 steps of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXlUBIkeGgih"
   },
   "source": [
    "### Train the Model\n",
    "\n",
    "Now we're ready to train our model, which we can do by creating `train_input_fn`\n",
    "and calling `train()` on `mnist_classifier`. In the `numpy_input_fn` call, we pass the training feature data and labels to\n",
    "`x` (as a dict) and `y`, respectively. We set a `batch_size` of `100` (which\n",
    "means that the model will train on minibatches of 100 examples at each step).\n",
    "`num_epochs=None` means that the model will train until the specified number of\n",
    "steps is reached. We also set `shuffle=True` to shuffle the training data. Then train the model a single step and log the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HTJ3GLXf6j5w",
    "outputId": "39f1c9f3-d1b2-449e-f471-a42616c9b22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-2-16a10fb7f348>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-16a10fb7f348>:15: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-16a10fb7f348>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-16a10fb7f348>:30: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.10693731 0.11082482 0.09896436 0.10868216 0.08797888 0.08350387\n",
      "  0.10289844 0.09755148 0.09922405 0.1034346 ]\n",
      " [0.10004145 0.08553869 0.10670968 0.09531603 0.09946866 0.08972938\n",
      "  0.08887909 0.12644888 0.0990386  0.10882956]\n",
      " [0.10020675 0.09351952 0.11157539 0.09792421 0.09051589 0.08694287\n",
      "  0.11060837 0.10450387 0.10127529 0.10292783]\n",
      " [0.10336086 0.10656906 0.10085827 0.09396193 0.09769213 0.09822625\n",
      "  0.09917598 0.10524224 0.09355884 0.10135448]\n",
      " [0.09770089 0.10379812 0.11057994 0.09485905 0.09268336 0.10547955\n",
      "  0.09838771 0.09828532 0.09443958 0.10378645]\n",
      " [0.10451447 0.09642053 0.1157806  0.09037595 0.09285133 0.0845006\n",
      "  0.09872272 0.11003455 0.10064111 0.1061582 ]\n",
      " [0.10717139 0.10531677 0.09819047 0.09894814 0.08935116 0.09476098\n",
      "  0.09317922 0.09730405 0.10426473 0.11151309]\n",
      " [0.10627359 0.09992176 0.10127973 0.0946558  0.10084501 0.09419675\n",
      "  0.09603683 0.10456688 0.1043074  0.09791618]\n",
      " [0.09982783 0.10603169 0.10458568 0.0931187  0.09739956 0.10892062\n",
      "  0.09332476 0.10140065 0.10057563 0.09481484]\n",
      " [0.09925032 0.09823816 0.10979741 0.09659201 0.09721211 0.10700089\n",
      "  0.10358702 0.09534189 0.09853826 0.09444185]\n",
      " [0.10053731 0.09191364 0.10889703 0.1005071  0.0946661  0.0952033\n",
      "  0.09207863 0.11285602 0.09812425 0.10521659]\n",
      " [0.09875782 0.09825183 0.10950658 0.09292133 0.09680972 0.09819533\n",
      "  0.09536157 0.11131676 0.08855805 0.11032096]\n",
      " [0.11444511 0.09243309 0.10217929 0.09683748 0.09631638 0.09595171\n",
      "  0.09436475 0.10523079 0.09045151 0.11178993]\n",
      " [0.10121965 0.09625578 0.11382693 0.09130117 0.09610097 0.10524661\n",
      "  0.09295159 0.11420117 0.09640274 0.09249336]\n",
      " [0.10382815 0.10631924 0.09438191 0.09345821 0.09931006 0.09892313\n",
      "  0.10026134 0.09501556 0.10208438 0.10641795]\n",
      " [0.10023087 0.10388025 0.09732562 0.09052705 0.10295971 0.10177898\n",
      "  0.09488557 0.1046146  0.10185274 0.10194454]\n",
      " [0.11808242 0.10267984 0.09355757 0.08283964 0.09985775 0.09119758\n",
      "  0.09873552 0.10180578 0.10576684 0.10547712]\n",
      " [0.11329452 0.10017594 0.09648551 0.09063128 0.08937386 0.09756733\n",
      "  0.095617   0.1082317  0.0974751  0.11114771]\n",
      " [0.1068818  0.09122247 0.10673568 0.09914288 0.09863602 0.09603561\n",
      "  0.08894636 0.09857695 0.10832683 0.10549536]\n",
      " [0.10611356 0.09857081 0.10881194 0.09710273 0.09374358 0.08937065\n",
      "  0.09941985 0.10391082 0.09872493 0.1042312 ]\n",
      " [0.10623749 0.10265364 0.10722732 0.09068362 0.09702446 0.09227739\n",
      "  0.09191398 0.11596733 0.09448328 0.10153154]\n",
      " [0.101129   0.11001202 0.10265168 0.08901168 0.10396142 0.09755819\n",
      "  0.09557682 0.09659314 0.10028759 0.10321844]\n",
      " [0.09961882 0.09741373 0.10667772 0.09495766 0.09024711 0.09765744\n",
      "  0.10103302 0.0982459  0.09631512 0.11783343]\n",
      " [0.10244324 0.09470814 0.09052098 0.0990691  0.09728847 0.0929926\n",
      "  0.1029002  0.10931519 0.10466748 0.10609461]\n",
      " [0.09945452 0.08569251 0.11032376 0.09702984 0.10250118 0.09607293\n",
      "  0.09806338 0.1039226  0.10029264 0.10664669]\n",
      " [0.09678063 0.10649751 0.10580145 0.08962049 0.09422147 0.08779059\n",
      "  0.09671901 0.10671742 0.10300697 0.11284444]\n",
      " [0.09525181 0.1059498  0.1187489  0.08381896 0.10460082 0.09463581\n",
      "  0.09655489 0.10665039 0.09686278 0.09692579]\n",
      " [0.10827602 0.10732862 0.09880755 0.0879772  0.10037125 0.08736547\n",
      "  0.10287657 0.10792006 0.09631725 0.10276002]\n",
      " [0.10942815 0.09284765 0.10238501 0.09031524 0.10765252 0.10256951\n",
      "  0.10269389 0.09067103 0.10210102 0.099336  ]\n",
      " [0.10345139 0.10735641 0.10443942 0.09715915 0.09314254 0.09740892\n",
      "  0.11150794 0.09882534 0.09304284 0.09366602]\n",
      " [0.09246831 0.09762993 0.10624883 0.09682611 0.09647606 0.09219769\n",
      "  0.10642224 0.10188764 0.10186022 0.10798296]\n",
      " [0.10255601 0.09807771 0.11271386 0.08049133 0.09844524 0.10313023\n",
      "  0.10135061 0.09735388 0.09756403 0.10831711]\n",
      " [0.1089071  0.09883898 0.10771468 0.10038906 0.10003999 0.08528217\n",
      "  0.0930895  0.10180963 0.10209303 0.10183585]\n",
      " [0.09991543 0.09540114 0.10535374 0.08342365 0.10033272 0.10423195\n",
      "  0.08926965 0.09625193 0.10024535 0.12557441]\n",
      " [0.09874596 0.09607404 0.10700508 0.09688791 0.09149837 0.09893221\n",
      "  0.10314465 0.10618217 0.09490977 0.10661978]\n",
      " [0.10110887 0.11148988 0.09819908 0.0822366  0.09938718 0.08227531\n",
      "  0.09582471 0.10595559 0.1230555  0.1004673 ]\n",
      " [0.10924414 0.09672397 0.10800938 0.09089119 0.10650984 0.10238845\n",
      "  0.105896   0.08982605 0.087045   0.10346598]\n",
      " [0.09471934 0.10132503 0.10954885 0.08692218 0.09822965 0.10426778\n",
      "  0.10000287 0.10517856 0.09620669 0.10359912]\n",
      " [0.09742037 0.10962342 0.11501616 0.0962376  0.08868592 0.09559952\n",
      "  0.09823102 0.1019586  0.08829895 0.10892843]\n",
      " [0.09931885 0.10404775 0.10231722 0.09759673 0.10978133 0.0901302\n",
      "  0.09632929 0.09492567 0.09471879 0.11083417]\n",
      " [0.09294244 0.10307093 0.10813488 0.09560037 0.09343158 0.09898803\n",
      "  0.09805132 0.09580532 0.09360196 0.12037323]\n",
      " [0.11061867 0.09971415 0.0951934  0.08795419 0.09972271 0.09886588\n",
      "  0.0962273  0.103084   0.11234997 0.09626967]\n",
      " [0.0936934  0.10322765 0.10111022 0.08689681 0.10392892 0.09898596\n",
      "  0.09935139 0.09799295 0.09949364 0.11531904]\n",
      " [0.12019409 0.09910093 0.10339852 0.09172296 0.09185012 0.0980159\n",
      "  0.08764847 0.10571133 0.09534653 0.10701111]\n",
      " [0.10613019 0.09860867 0.10359355 0.08854459 0.09903624 0.09049923\n",
      "  0.09922054 0.10533638 0.10184172 0.10718888]\n",
      " [0.10680392 0.09725884 0.09862333 0.095061   0.09717072 0.10391179\n",
      "  0.0917023  0.10420996 0.09895179 0.10630637]\n",
      " [0.10360564 0.09518181 0.10317267 0.10829106 0.09007031 0.09477949\n",
      "  0.09456327 0.10996164 0.09599733 0.10437682]\n",
      " [0.10568497 0.10377277 0.10278773 0.10226306 0.09296787 0.08990835\n",
      "  0.09196681 0.09962344 0.11092096 0.10010409]\n",
      " [0.10597742 0.10854638 0.10165352 0.0960332  0.0994634  0.0841985\n",
      "  0.09722155 0.09148434 0.10707241 0.10834936]\n",
      " [0.11122844 0.1053338  0.10802747 0.09630916 0.0909711  0.0904379\n",
      "  0.0912132  0.10650803 0.10090613 0.0990648 ]\n",
      " [0.10710789 0.1026089  0.1124135  0.08970784 0.0865742  0.0929893\n",
      "  0.09841157 0.10226167 0.08943325 0.11849187]\n",
      " [0.10191446 0.11512917 0.09205445 0.09127489 0.09714761 0.10337012\n",
      "  0.10144357 0.10556138 0.09343002 0.09867433]\n",
      " [0.09833652 0.10398693 0.10122265 0.09735806 0.09532466 0.09588544\n",
      "  0.08769819 0.10383017 0.10320269 0.11315474]\n",
      " [0.10774001 0.08996697 0.09513111 0.09025296 0.10098138 0.10398027\n",
      "  0.0926082  0.1060655  0.09555792 0.11771562]\n",
      " [0.10830849 0.10304317 0.10480263 0.09011549 0.09523845 0.09728482\n",
      "  0.09392022 0.10330986 0.10074645 0.10323038]\n",
      " [0.10742141 0.10049503 0.1073953  0.08286186 0.09725198 0.09549709\n",
      "  0.10462878 0.10364261 0.1036948  0.09711122]\n",
      " [0.1001766  0.10116614 0.09912762 0.08752129 0.09918397 0.10506424\n",
      "  0.09899002 0.10909481 0.09220646 0.1074689 ]\n",
      " [0.09717944 0.10788828 0.11251049 0.09213592 0.09986749 0.0949433\n",
      "  0.09442756 0.10126466 0.10068105 0.09910174]\n",
      " [0.10732713 0.11168373 0.11080153 0.08730707 0.09935577 0.09564732\n",
      "  0.09608632 0.09314438 0.09421211 0.10443456]\n",
      " [0.10586827 0.09998745 0.10064022 0.09655698 0.09216945 0.08971901\n",
      "  0.09659538 0.11334882 0.09644402 0.10867035]\n",
      " [0.10123564 0.09969068 0.11088429 0.09713037 0.09293592 0.09888257\n",
      "  0.09756412 0.10482185 0.09056815 0.10628649]\n",
      " [0.11172839 0.09995792 0.10344558 0.09234109 0.09572733 0.09941723\n",
      "  0.10232829 0.09445442 0.10141255 0.09918719]\n",
      " [0.10744117 0.10145704 0.10146437 0.09520411 0.09401662 0.09949802\n",
      "  0.09532919 0.09849817 0.10048889 0.1066024 ]\n",
      " [0.10557681 0.08988141 0.09594871 0.0887382  0.1033012  0.09514142\n",
      "  0.1043174  0.11844967 0.10119963 0.09744555]\n",
      " [0.10761801 0.10005064 0.11039927 0.0805683  0.10352518 0.0854205\n",
      "  0.1079815  0.08974639 0.10477871 0.10991149]\n",
      " [0.09272497 0.08759448 0.11680169 0.10129712 0.10534325 0.09264095\n",
      "  0.09986789 0.10398827 0.08830154 0.11143984]\n",
      " [0.11154792 0.08785575 0.09870487 0.08841421 0.10541901 0.09238228\n",
      "  0.09898761 0.11272276 0.09855726 0.1054083 ]\n",
      " [0.1088435  0.09995347 0.10540754 0.09493926 0.08954709 0.09061049\n",
      "  0.1015691  0.10036122 0.09752404 0.11124431]\n",
      " [0.10554922 0.1047792  0.12352049 0.1005495  0.0995331  0.08763564\n",
      "  0.09171219 0.09044227 0.09808496 0.09819348]\n",
      " [0.10075867 0.10499685 0.09628944 0.09825217 0.09627888 0.08470416\n",
      "  0.10943926 0.1078551  0.09522599 0.10619944]\n",
      " [0.10512878 0.09509709 0.10956364 0.09067956 0.08913493 0.10074139\n",
      "  0.10113452 0.10255507 0.10293891 0.10302606]\n",
      " [0.10250697 0.09464458 0.10333326 0.09021594 0.10096341 0.10558335\n",
      "  0.09541831 0.10223956 0.10223615 0.10285846]\n",
      " [0.10139169 0.09982805 0.09720378 0.09157824 0.08740509 0.10251743\n",
      "  0.10806238 0.09986428 0.10376076 0.1083883 ]\n",
      " [0.10633644 0.10297428 0.09577034 0.09863322 0.09834761 0.08839168\n",
      "  0.10351838 0.09205664 0.09788134 0.11609008]\n",
      " [0.09298082 0.10426534 0.10705222 0.09198014 0.09306895 0.09849256\n",
      "  0.09834477 0.10733162 0.10132027 0.10516332]\n",
      " [0.10658708 0.10592593 0.09462577 0.09164391 0.10215936 0.0902601\n",
      "  0.10276045 0.10542251 0.09537862 0.10523622]\n",
      " [0.11008991 0.09632198 0.11140274 0.09672359 0.09555081 0.10449968\n",
      "  0.09043373 0.09427536 0.09413434 0.10656781]\n",
      " [0.09925688 0.10120026 0.10140226 0.09467733 0.09719313 0.09997551\n",
      "  0.10070053 0.09613062 0.09951911 0.10994433]\n",
      " [0.107198   0.09861376 0.1062621  0.09695398 0.09669654 0.09473959\n",
      "  0.1034117  0.10224874 0.09339456 0.10048104]\n",
      " [0.08854282 0.10146429 0.10459649 0.09654339 0.09539296 0.10478023\n",
      "  0.09776977 0.10411215 0.10475401 0.10204386]\n",
      " [0.09201717 0.10064064 0.09676035 0.09565885 0.09344167 0.10295298\n",
      "  0.10964204 0.10273865 0.09703071 0.10911694]\n",
      " [0.10701204 0.09734122 0.10362355 0.08715335 0.09655163 0.10321334\n",
      "  0.10025816 0.10966081 0.09995227 0.0952336 ]\n",
      " [0.09668712 0.09937451 0.09732455 0.09289746 0.10163204 0.09768761\n",
      "  0.10608196 0.10999727 0.09797622 0.10034122]\n",
      " [0.10038687 0.10061948 0.1129952  0.09419107 0.111246   0.08464658\n",
      "  0.10271191 0.09852995 0.10425684 0.09041602]\n",
      " [0.10657629 0.09636834 0.11007378 0.09283516 0.10120055 0.08953347\n",
      "  0.10593735 0.10040613 0.09642544 0.10064343]\n",
      " [0.09975041 0.10768349 0.10869779 0.09065439 0.09077955 0.09719423\n",
      "  0.10619228 0.10297009 0.10539252 0.09068521]\n",
      " [0.10038183 0.08610258 0.10575553 0.08316431 0.10376859 0.11110204\n",
      "  0.09515429 0.10383543 0.09907269 0.11166269]\n",
      " [0.1075018  0.09929772 0.10204642 0.08470257 0.09962621 0.10749676\n",
      "  0.10492118 0.1128927  0.08628199 0.09523263]\n",
      " [0.09294455 0.09695362 0.10502023 0.08644031 0.10231993 0.08670568\n",
      "  0.10641474 0.10980728 0.10210419 0.11128952]\n",
      " [0.10760488 0.10036246 0.10278564 0.09444609 0.09560039 0.09553881\n",
      "  0.09586255 0.10426245 0.10205999 0.10147675]\n",
      " [0.11032807 0.10213899 0.10196628 0.09087915 0.0949673  0.09579767\n",
      "  0.09364116 0.10609364 0.10179909 0.10238861]\n",
      " [0.10797877 0.10224511 0.09864939 0.09824091 0.09430482 0.0892249\n",
      "  0.10821494 0.10269161 0.10229305 0.09615645]\n",
      " [0.10289201 0.10715978 0.0989407  0.09365566 0.09979207 0.09898347\n",
      "  0.10115817 0.10046663 0.09700163 0.09994985]\n",
      " [0.10652919 0.09509543 0.10227109 0.09736715 0.10115615 0.09768756\n",
      "  0.0963325  0.10588796 0.09383932 0.10383362]\n",
      " [0.09796394 0.09445839 0.1144215  0.08645396 0.10399243 0.09332569\n",
      "  0.10187591 0.09452768 0.09558298 0.11739747]\n",
      " [0.10345002 0.09929363 0.09783689 0.09305447 0.10476717 0.09947632\n",
      "  0.09913318 0.10519035 0.09670448 0.1010935 ]\n",
      " [0.11166618 0.0949526  0.09955154 0.09016078 0.09802861 0.11389998\n",
      "  0.09143216 0.09653164 0.09861227 0.1051643 ]\n",
      " [0.10792363 0.09835828 0.09863646 0.09096608 0.10504384 0.09850305\n",
      "  0.10079268 0.0938593  0.0992584  0.1066583 ]\n",
      " [0.10625377 0.10097029 0.0998061  0.09206398 0.0941743  0.09673428\n",
      "  0.09805884 0.09309231 0.10670386 0.11214227]\n",
      " [0.10985405 0.09645811 0.10454925 0.08192892 0.09166277 0.10112306\n",
      "  0.0902938  0.10046063 0.10277575 0.12089369]]\n",
      "INFO:tensorflow:loss = 2.3013973, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.3013973.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f347f438390>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ktoj_2mhGyje"
   },
   "source": [
    "Now—without logging each step—set `steps=1000` to train the model longer, but in a reasonable time to run this example. Training CNNs is computationally intensive. To increase the accuracy of your model, increase the number of `steps` passed to `train()`, like 20,000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Df2PU06X6n6U",
    "outputId": "065b8bcd-cd9d-4dc2-a1df-c5de3c9fea73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.315087, step = 1\n",
      "INFO:tensorflow:global_step/sec: 80.5193\n",
      "INFO:tensorflow:loss = 2.2959542, step = 101 (1.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0775\n",
      "INFO:tensorflow:loss = 2.291102, step = 201 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.5585\n",
      "INFO:tensorflow:loss = 2.269744, step = 301 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6407\n",
      "INFO:tensorflow:loss = 2.253468, step = 401 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9349\n",
      "INFO:tensorflow:loss = 2.2172647, step = 501 (1.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2906\n",
      "INFO:tensorflow:loss = 2.224275, step = 601 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.713\n",
      "INFO:tensorflow:loss = 2.2038481, step = 701 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7551\n",
      "INFO:tensorflow:loss = 2.163476, step = 801 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.5829\n",
      "INFO:tensorflow:loss = 2.1469884, step = 901 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4021\n",
      "INFO:tensorflow:loss = 2.099287, step = 1001 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.9741\n",
      "INFO:tensorflow:loss = 2.027104, step = 1101 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0429\n",
      "INFO:tensorflow:loss = 1.9474484, step = 1201 (1.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2948\n",
      "INFO:tensorflow:loss = 1.8512284, step = 1301 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.2064\n",
      "INFO:tensorflow:loss = 1.7507312, step = 1401 (1.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.395\n",
      "INFO:tensorflow:loss = 1.4838179, step = 1501 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0785\n",
      "INFO:tensorflow:loss = 1.3415065, step = 1601 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1614\n",
      "INFO:tensorflow:loss = 1.1720526, step = 1701 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3377\n",
      "INFO:tensorflow:loss = 1.2183553, step = 1801 (1.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.5449\n",
      "INFO:tensorflow:loss = 0.9685182, step = 1901 (1.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4012\n",
      "INFO:tensorflow:loss = 0.9278633, step = 2001 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.717\n",
      "INFO:tensorflow:loss = 0.8485926, step = 2101 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9168\n",
      "INFO:tensorflow:loss = 0.72694796, step = 2201 (1.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1574\n",
      "INFO:tensorflow:loss = 0.67275447, step = 2301 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4364\n",
      "INFO:tensorflow:loss = 0.66185224, step = 2401 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.094\n",
      "INFO:tensorflow:loss = 0.5551054, step = 2501 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.7947\n",
      "INFO:tensorflow:loss = 0.57229537, step = 2601 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.5209\n",
      "INFO:tensorflow:loss = 0.61819094, step = 2701 (1.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1537\n",
      "INFO:tensorflow:loss = 0.6429645, step = 2801 (1.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.6224\n",
      "INFO:tensorflow:loss = 0.55191475, step = 2901 (1.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0758\n",
      "INFO:tensorflow:loss = 0.4653548, step = 3001 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.002\n",
      "INFO:tensorflow:loss = 0.38318393, step = 3101 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9542\n",
      "INFO:tensorflow:loss = 0.44748998, step = 3201 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6004\n",
      "INFO:tensorflow:loss = 0.51256466, step = 3301 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3292\n",
      "INFO:tensorflow:loss = 0.48272097, step = 3401 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3682\n",
      "INFO:tensorflow:loss = 0.43554628, step = 3501 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4707\n",
      "INFO:tensorflow:loss = 0.47362068, step = 3601 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4806\n",
      "INFO:tensorflow:loss = 0.58549124, step = 3701 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4039\n",
      "INFO:tensorflow:loss = 0.4508277, step = 3801 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.7067\n",
      "INFO:tensorflow:loss = 0.38116896, step = 3901 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.7316\n",
      "INFO:tensorflow:loss = 0.46568644, step = 4001 (1.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.887\n",
      "INFO:tensorflow:loss = 0.516694, step = 4101 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8201\n",
      "INFO:tensorflow:loss = 0.46706757, step = 4201 (1.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2689\n",
      "INFO:tensorflow:loss = 0.35402778, step = 4301 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.5087\n",
      "INFO:tensorflow:loss = 0.2531004, step = 4401 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.0973\n",
      "INFO:tensorflow:loss = 0.3788255, step = 4501 (1.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0057\n",
      "INFO:tensorflow:loss = 0.46722862, step = 4601 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9086\n",
      "INFO:tensorflow:loss = 0.2669656, step = 4701 (1.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7357\n",
      "INFO:tensorflow:loss = 0.32511243, step = 4801 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0438\n",
      "INFO:tensorflow:loss = 0.32369408, step = 4901 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.6087\n",
      "INFO:tensorflow:loss = 0.327813, step = 5001 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1109\n",
      "INFO:tensorflow:loss = 0.37863663, step = 5101 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3835\n",
      "INFO:tensorflow:loss = 0.37351117, step = 5201 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4596\n",
      "INFO:tensorflow:loss = 0.37034515, step = 5301 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.7535\n",
      "INFO:tensorflow:loss = 0.34859246, step = 5401 (1.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2668\n",
      "INFO:tensorflow:loss = 0.17421523, step = 5501 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2537\n",
      "INFO:tensorflow:loss = 0.29188472, step = 5601 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9254\n",
      "INFO:tensorflow:loss = 0.3750655, step = 5701 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4656\n",
      "INFO:tensorflow:loss = 0.22132201, step = 5801 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0606\n",
      "INFO:tensorflow:loss = 0.28015092, step = 5901 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6433\n",
      "INFO:tensorflow:loss = 0.3574514, step = 6001 (1.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.5943\n",
      "INFO:tensorflow:loss = 0.31483355, step = 6101 (1.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5415\n",
      "INFO:tensorflow:loss = 0.24565656, step = 6201 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.0732\n",
      "INFO:tensorflow:loss = 0.33392856, step = 6301 (1.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2165\n",
      "INFO:tensorflow:loss = 0.25919732, step = 6401 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.5067\n",
      "INFO:tensorflow:loss = 0.35787687, step = 6501 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7396\n",
      "INFO:tensorflow:loss = 0.28698757, step = 6601 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7146\n",
      "INFO:tensorflow:loss = 0.32858607, step = 6701 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1343\n",
      "INFO:tensorflow:loss = 0.3510511, step = 6801 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4003\n",
      "INFO:tensorflow:loss = 0.28727108, step = 6901 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.7062\n",
      "INFO:tensorflow:loss = 0.2441644, step = 7001 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.6483\n",
      "INFO:tensorflow:loss = 0.2954586, step = 7101 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1762\n",
      "INFO:tensorflow:loss = 0.19137575, step = 7201 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2338\n",
      "INFO:tensorflow:loss = 0.2076547, step = 7301 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.9448\n",
      "INFO:tensorflow:loss = 0.29748875, step = 7401 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.0924\n",
      "INFO:tensorflow:loss = 0.28905952, step = 7501 (1.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1495\n",
      "INFO:tensorflow:loss = 0.07882536, step = 7601 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3352\n",
      "INFO:tensorflow:loss = 0.22830358, step = 7701 (1.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.465\n",
      "INFO:tensorflow:loss = 0.35858482, step = 7801 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.3689\n",
      "INFO:tensorflow:loss = 0.15024163, step = 7901 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9356\n",
      "INFO:tensorflow:loss = 0.2753204, step = 8001 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.5443\n",
      "INFO:tensorflow:loss = 0.1761087, step = 8101 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6786\n",
      "INFO:tensorflow:loss = 0.18014227, step = 8201 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.5396\n",
      "INFO:tensorflow:loss = 0.32334712, step = 8301 (1.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2675\n",
      "INFO:tensorflow:loss = 0.2690299, step = 8401 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.3254\n",
      "INFO:tensorflow:loss = 0.2431813, step = 8501 (1.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.9244\n",
      "INFO:tensorflow:loss = 0.26371863, step = 8601 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.5689\n",
      "INFO:tensorflow:loss = 0.16832292, step = 8701 (1.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1158\n",
      "INFO:tensorflow:loss = 0.15426736, step = 8801 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.2739\n",
      "INFO:tensorflow:loss = 0.18680537, step = 8901 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1601\n",
      "INFO:tensorflow:loss = 0.170553, step = 9001 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7021\n",
      "INFO:tensorflow:loss = 0.20131738, step = 9101 (1.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4879\n",
      "INFO:tensorflow:loss = 0.2927566, step = 9201 (1.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0215\n",
      "INFO:tensorflow:loss = 0.41017604, step = 9301 (1.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0233\n",
      "INFO:tensorflow:loss = 0.18977074, step = 9401 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4187\n",
      "INFO:tensorflow:loss = 0.26573035, step = 9501 (1.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8069\n",
      "INFO:tensorflow:loss = 0.20791887, step = 9601 (1.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.9246\n",
      "INFO:tensorflow:loss = 0.26668248, step = 9701 (1.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8421\n",
      "INFO:tensorflow:loss = 0.24527653, step = 9801 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.9906\n",
      "INFO:tensorflow:loss = 0.18660142, step = 9901 (1.050 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1785429.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f347f438390>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(input_fn=train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "8xFLiszT6umY",
    "outputId": "9863b803-1882-4cf1-918e-3fc9316a34e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-30T09:27:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-10001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-30-09:27:21\n",
      "INFO:tensorflow:Saving dict for global step 10001: accuracy = 0.9534, global_step = 10001, loss = 0.16254406\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10001: /tmp/mnist_convnet_model/model.ckpt-10001\n",
      "{'accuracy': 0.9534, 'loss': 0.16254406, 'global_step': 10001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VI9_MXOQ1xVN",
    "outputId": "66102839-f704-4dd5-867b-b1412233353a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "uTm-RbNV17xV",
    "outputId": "63c79cfe-1a27-457b-f39c-1948688f9826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'tmp'\n",
      "/root\n"
     ]
    }
   ],
   "source": [
    "%cd tmp"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Tensorflow MNIST Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
