{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPlR2yyAjvPb"
   },
   "source": [
    "Our task is to make a simple DL classifer to correctly classify frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8WLTlbki--7"
   },
   "outputs": [],
   "source": [
    "# Starting with useful imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "fra2tKmfwxd8",
    "outputId": "c4f570ec-fbba-450c-ae16-f484e1c6b50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-6tCHJXRzJWg",
    "outputId": "231f354f-20b4-40af-f835-e5d4d0a81271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "jf6gG-oKk0xd",
    "outputId": "c813fdf3-e53d-4e86-ea22-3f9a8f8f7cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "fname = 'My Drive/data/creditcard.csv'\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "  for i, line in enumerate(f):\n",
    "    if i == 0:\n",
    "      print('HEADER:', line.strip())\n",
    "      continue  # Skip header\n",
    "    fields = line.strip().split(',')\n",
    "    all_features.append([float(v.replace('\"', '')) for v in fields[:-1]])\n",
    "    all_targets.append([int(fields[-1].replace('\"', ''))])\n",
    "    if i == 1:\n",
    "      print('EXAMPLE FEATURES:', all_features[-1])\n",
    "    \n",
    "features = np.array(all_features, dtype='float32')\n",
    "targets = np.array(all_targets, dtype='uint8')\n",
    "print('features.shape:', features.shape)\n",
    "print('targets.shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "i7PMGXdEk53Z",
    "outputId": "f0ee4dfa-b390-4cbb-d0a9-61f9d2e10bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of test samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_test_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_test_samples]\n",
    "train_targets = targets[:-num_test_samples]\n",
    "test_features = features[-num_test_samples:]\n",
    "test_targets = targets[-num_test_samples:]\n",
    "print('Number of training samples:', len(train_features))\n",
    "print('Number of test samples:', len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LgHaMfUtlOZj",
    "outputId": "fc90bb72-a6bd-4b0e-dbd3-248dd995fdfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print('Number of positive samples in training data: {} ({:.2f}% of total)'.format(counts[1], 100 * float(counts[1]) / len(train_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z7uHmVq5txZK",
    "outputId": "57538761-cef5-4104-9abe-2119b67e78de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in testing data: 75 (0.13% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(test_targets[:, 0])\n",
    "print('Number of positive samples in testing data: {} ({:.2f}% of total)'.format(counts[1], 100 * float(counts[1]) / len(test_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgYkz7W3lX_a"
   },
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "test_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "test_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "l8R0Ga_Ut-xd",
    "outputId": "ac8ee250-f52d-4a0c-f709-90bb465770ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227846, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "ISKRObCClfoF",
    "outputId": "dba70073-c52f-4807-e881-c0b79b29e78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              31744     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 720,897\n",
      "Trainable params: 720,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "session = keras.backend.get_session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(1024, activation='relu',\n",
    "                     input_shape=(train_features.shape[-1],)),\n",
    "  keras.layers.Dense(512, activation='tanh'),\n",
    "  keras.layers.Dropout(0.25),\n",
    "  keras.layers.Dense(256, activation='relu'),\n",
    "  keras.layers.Dropout(0.40),\n",
    "  keras.layers.Dense(128, activation='elu'),\n",
    "  keras.layers.Dropout(0.40),\n",
    "  keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "0MKGs-BCvRoP",
    "outputId": "d7b09f38-978d-4ff3-81d5-2031b71ce7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "d-93q37XliPY",
    "outputId": "b3f1e92d-6493-4597-b01a-9b8988a17e13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227846 samples, validate on 56961 samples\n",
      "Epoch 1/100\n",
      "227846/227846 - 1s - loss: 0.5196 - fn: 71.0000 - fp: 7932.0000 - tn: 219497.0000 - tp: 346.0000 - precision: 0.0418 - recall: 0.8297 - accuracy: 0.0813 - val_loss: 0.0153 - val_fn: 14.0000 - val_fp: 85.0000 - val_tn: 56801.0000 - val_tp: 61.0000 - val_precision: 0.4178 - val_recall: 0.8133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "227846/227846 - 1s - loss: 0.1740 - fn: 45.0000 - fp: 2758.0000 - tn: 224671.0000 - tp: 372.0000 - precision: 0.1188 - recall: 0.8921 - accuracy: 0.0266 - val_loss: 0.0164 - val_fn: 15.0000 - val_fp: 30.0000 - val_tn: 56856.0000 - val_tp: 60.0000 - val_precision: 0.6667 - val_recall: 0.8000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "227846/227846 - 1s - loss: 0.1557 - fn: 36.0000 - fp: 2657.0000 - tn: 224772.0000 - tp: 381.0000 - precision: 0.1254 - recall: 0.9137 - accuracy: 0.0261 - val_loss: 0.0082 - val_fn: 13.0000 - val_fp: 72.0000 - val_tn: 56814.0000 - val_tp: 62.0000 - val_precision: 0.4627 - val_recall: 0.8267 - val_accuracy: 0.0016\n",
      "Epoch 4/100\n",
      "227846/227846 - 1s - loss: 0.1716 - fn: 39.0000 - fp: 2495.0000 - tn: 224934.0000 - tp: 378.0000 - precision: 0.1316 - recall: 0.9065 - accuracy: 0.0576 - val_loss: 0.0425 - val_fn: 12.0000 - val_fp: 242.0000 - val_tn: 56644.0000 - val_tp: 63.0000 - val_precision: 0.2066 - val_recall: 0.8400 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "227846/227846 - 1s - loss: 0.1603 - fn: 32.0000 - fp: 2691.0000 - tn: 224738.0000 - tp: 385.0000 - precision: 0.1252 - recall: 0.9233 - accuracy: 0.0660 - val_loss: 0.0207 - val_fn: 14.0000 - val_fp: 182.0000 - val_tn: 56704.0000 - val_tp: 61.0000 - val_precision: 0.2510 - val_recall: 0.8133 - val_accuracy: 6.3201e-04\n",
      "Epoch 6/100\n",
      "227846/227846 - 1s - loss: 0.1374 - fn: 36.0000 - fp: 3160.0000 - tn: 224269.0000 - tp: 381.0000 - precision: 0.1076 - recall: 0.9137 - accuracy: 0.0631 - val_loss: 0.0103 - val_fn: 13.0000 - val_fp: 91.0000 - val_tn: 56795.0000 - val_tp: 62.0000 - val_precision: 0.4052 - val_recall: 0.8267 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "227846/227846 - 1s - loss: 0.1297 - fn: 30.0000 - fp: 2339.0000 - tn: 225090.0000 - tp: 387.0000 - precision: 0.1420 - recall: 0.9281 - accuracy: 0.0374 - val_loss: 0.0252 - val_fn: 11.0000 - val_fp: 188.0000 - val_tn: 56698.0000 - val_tp: 64.0000 - val_precision: 0.2540 - val_recall: 0.8533 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "227846/227846 - 1s - loss: 0.1254 - fn: 26.0000 - fp: 2113.0000 - tn: 225316.0000 - tp: 391.0000 - precision: 0.1562 - recall: 0.9376 - accuracy: 0.1098 - val_loss: 0.0147 - val_fn: 13.0000 - val_fp: 84.0000 - val_tn: 56802.0000 - val_tp: 62.0000 - val_precision: 0.4247 - val_recall: 0.8267 - val_accuracy: 0.0018\n",
      "Epoch 9/100\n",
      "227846/227846 - 1s - loss: 0.1197 - fn: 27.0000 - fp: 2276.0000 - tn: 225153.0000 - tp: 390.0000 - precision: 0.1463 - recall: 0.9353 - accuracy: 0.1184 - val_loss: 0.0239 - val_fn: 11.0000 - val_fp: 241.0000 - val_tn: 56645.0000 - val_tp: 64.0000 - val_precision: 0.2098 - val_recall: 0.8533 - val_accuracy: 0.0508\n",
      "Epoch 10/100\n",
      "227846/227846 - 1s - loss: 0.1462 - fn: 31.0000 - fp: 2426.0000 - tn: 225003.0000 - tp: 386.0000 - precision: 0.1373 - recall: 0.9257 - accuracy: 0.1818 - val_loss: 0.0060 - val_fn: 15.0000 - val_fp: 53.0000 - val_tn: 56833.0000 - val_tp: 60.0000 - val_precision: 0.5310 - val_recall: 0.8000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "227846/227846 - 1s - loss: 0.1587 - fn: 28.0000 - fp: 2071.0000 - tn: 225358.0000 - tp: 389.0000 - precision: 0.1581 - recall: 0.9329 - accuracy: 0.0633 - val_loss: 0.0115 - val_fn: 16.0000 - val_fp: 42.0000 - val_tn: 56844.0000 - val_tp: 59.0000 - val_precision: 0.5842 - val_recall: 0.7867 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "227846/227846 - 1s - loss: 0.1029 - fn: 25.0000 - fp: 1866.0000 - tn: 225563.0000 - tp: 392.0000 - precision: 0.1736 - recall: 0.9400 - accuracy: 0.0893 - val_loss: 0.0066 - val_fn: 12.0000 - val_fp: 81.0000 - val_tn: 56805.0000 - val_tp: 63.0000 - val_precision: 0.4375 - val_recall: 0.8400 - val_accuracy: 0.4150\n",
      "Epoch 13/100\n",
      "227846/227846 - 1s - loss: 0.1078 - fn: 22.0000 - fp: 1451.0000 - tn: 225978.0000 - tp: 395.0000 - precision: 0.2140 - recall: 0.9472 - accuracy: 0.2207 - val_loss: 0.0166 - val_fn: 14.0000 - val_fp: 57.0000 - val_tn: 56829.0000 - val_tp: 61.0000 - val_precision: 0.5169 - val_recall: 0.8133 - val_accuracy: 0.1939\n",
      "Epoch 14/100\n",
      "227846/227846 - 1s - loss: 0.1258 - fn: 27.0000 - fp: 2128.0000 - tn: 225301.0000 - tp: 390.0000 - precision: 0.1549 - recall: 0.9353 - accuracy: 0.3757 - val_loss: 0.0223 - val_fn: 12.0000 - val_fp: 324.0000 - val_tn: 56562.0000 - val_tp: 63.0000 - val_precision: 0.1628 - val_recall: 0.8400 - val_accuracy: 0.1983\n",
      "Epoch 15/100\n",
      "227846/227846 - 1s - loss: 0.1246 - fn: 34.0000 - fp: 2667.0000 - tn: 224762.0000 - tp: 383.0000 - precision: 0.1256 - recall: 0.9185 - accuracy: 0.3968 - val_loss: 0.0254 - val_fn: 7.0000 - val_fp: 412.0000 - val_tn: 56474.0000 - val_tp: 68.0000 - val_precision: 0.1417 - val_recall: 0.9067 - val_accuracy: 0.3239\n",
      "Epoch 16/100\n",
      "227846/227846 - 1s - loss: 0.1395 - fn: 36.0000 - fp: 2554.0000 - tn: 224875.0000 - tp: 381.0000 - precision: 0.1298 - recall: 0.9137 - accuracy: 0.3180 - val_loss: 0.0262 - val_fn: 11.0000 - val_fp: 264.0000 - val_tn: 56622.0000 - val_tp: 64.0000 - val_precision: 0.1951 - val_recall: 0.8533 - val_accuracy: 0.0086\n",
      "Epoch 17/100\n",
      "227846/227846 - 1s - loss: 0.1199 - fn: 26.0000 - fp: 2348.0000 - tn: 225081.0000 - tp: 391.0000 - precision: 0.1428 - recall: 0.9376 - accuracy: 0.2036 - val_loss: 0.0365 - val_fn: 9.0000 - val_fp: 406.0000 - val_tn: 56480.0000 - val_tp: 66.0000 - val_precision: 0.1398 - val_recall: 0.8800 - val_accuracy: 0.1581\n",
      "Epoch 18/100\n",
      "227846/227846 - 1s - loss: 0.1515 - fn: 29.0000 - fp: 3052.0000 - tn: 224377.0000 - tp: 388.0000 - precision: 0.1128 - recall: 0.9305 - accuracy: 0.1835 - val_loss: 0.0404 - val_fn: 9.0000 - val_fp: 559.0000 - val_tn: 56327.0000 - val_tp: 66.0000 - val_precision: 0.1056 - val_recall: 0.8800 - val_accuracy: 0.3264\n",
      "Epoch 19/100\n",
      "227846/227846 - 1s - loss: 0.1176 - fn: 24.0000 - fp: 2543.0000 - tn: 224886.0000 - tp: 393.0000 - precision: 0.1339 - recall: 0.9424 - accuracy: 0.3517 - val_loss: 0.0184 - val_fn: 12.0000 - val_fp: 217.0000 - val_tn: 56669.0000 - val_tp: 63.0000 - val_precision: 0.2250 - val_recall: 0.8400 - val_accuracy: 0.2495\n",
      "Epoch 20/100\n",
      "227846/227846 - 1s - loss: 0.0975 - fn: 23.0000 - fp: 2070.0000 - tn: 225359.0000 - tp: 394.0000 - precision: 0.1599 - recall: 0.9448 - accuracy: 0.3791 - val_loss: 0.0132 - val_fn: 11.0000 - val_fp: 187.0000 - val_tn: 56699.0000 - val_tp: 64.0000 - val_precision: 0.2550 - val_recall: 0.8533 - val_accuracy: 0.6175\n",
      "Epoch 21/100\n",
      "227846/227846 - 1s - loss: 0.1807 - fn: 37.0000 - fp: 3445.0000 - tn: 223984.0000 - tp: 380.0000 - precision: 0.0993 - recall: 0.9113 - accuracy: 0.5181 - val_loss: 0.0066 - val_fn: 15.0000 - val_fp: 63.0000 - val_tn: 56823.0000 - val_tp: 60.0000 - val_precision: 0.4878 - val_recall: 0.8000 - val_accuracy: 0.4155\n",
      "Epoch 22/100\n",
      "227846/227846 - 1s - loss: 0.2847 - fn: 34.0000 - fp: 3499.0000 - tn: 223930.0000 - tp: 383.0000 - precision: 0.0987 - recall: 0.9185 - accuracy: 0.4102 - val_loss: 0.0094 - val_fn: 13.0000 - val_fp: 106.0000 - val_tn: 56780.0000 - val_tp: 62.0000 - val_precision: 0.3690 - val_recall: 0.8267 - val_accuracy: 0.3560\n",
      "Epoch 23/100\n",
      "227846/227846 - 1s - loss: 0.1802 - fn: 35.0000 - fp: 3882.0000 - tn: 223547.0000 - tp: 382.0000 - precision: 0.0896 - recall: 0.9161 - accuracy: 0.3689 - val_loss: 0.0255 - val_fn: 9.0000 - val_fp: 319.0000 - val_tn: 56567.0000 - val_tp: 66.0000 - val_precision: 0.1714 - val_recall: 0.8800 - val_accuracy: 0.3540\n",
      "Epoch 24/100\n",
      "227846/227846 - 1s - loss: 0.1601 - fn: 31.0000 - fp: 3076.0000 - tn: 224353.0000 - tp: 386.0000 - precision: 0.1115 - recall: 0.9257 - accuracy: 0.2249 - val_loss: 0.0187 - val_fn: 14.0000 - val_fp: 84.0000 - val_tn: 56802.0000 - val_tp: 61.0000 - val_precision: 0.4207 - val_recall: 0.8133 - val_accuracy: 0.1555\n",
      "Epoch 25/100\n",
      "227846/227846 - 1s - loss: 0.1375 - fn: 28.0000 - fp: 2598.0000 - tn: 224831.0000 - tp: 389.0000 - precision: 0.1302 - recall: 0.9329 - accuracy: 0.4216 - val_loss: 0.0302 - val_fn: 11.0000 - val_fp: 239.0000 - val_tn: 56647.0000 - val_tp: 64.0000 - val_precision: 0.2112 - val_recall: 0.8533 - val_accuracy: 0.3784\n",
      "Epoch 26/100\n",
      "227846/227846 - 1s - loss: 0.2311 - fn: 38.0000 - fp: 4107.0000 - tn: 223322.0000 - tp: 379.0000 - precision: 0.0845 - recall: 0.9089 - accuracy: 0.4531 - val_loss: 0.0114 - val_fn: 13.0000 - val_fp: 95.0000 - val_tn: 56791.0000 - val_tp: 62.0000 - val_precision: 0.3949 - val_recall: 0.8267 - val_accuracy: 0.8633\n",
      "Epoch 27/100\n",
      "227846/227846 - 1s - loss: 0.2297 - fn: 41.0000 - fp: 4033.0000 - tn: 223396.0000 - tp: 376.0000 - precision: 0.0853 - recall: 0.9017 - accuracy: 0.4732 - val_loss: 0.0351 - val_fn: 15.0000 - val_fp: 35.0000 - val_tn: 56851.0000 - val_tp: 60.0000 - val_precision: 0.6316 - val_recall: 0.8000 - val_accuracy: 0.0060\n",
      "Epoch 28/100\n",
      "227846/227846 - 1s - loss: 0.1945 - fn: 36.0000 - fp: 2813.0000 - tn: 224616.0000 - tp: 381.0000 - precision: 0.1193 - recall: 0.9137 - accuracy: 0.2194 - val_loss: 0.0496 - val_fn: 11.0000 - val_fp: 340.0000 - val_tn: 56546.0000 - val_tp: 64.0000 - val_precision: 0.1584 - val_recall: 0.8533 - val_accuracy: 0.1605\n",
      "Epoch 29/100\n",
      "227846/227846 - 1s - loss: 0.1813 - fn: 36.0000 - fp: 2695.0000 - tn: 224734.0000 - tp: 381.0000 - precision: 0.1239 - recall: 0.9137 - accuracy: 0.1524 - val_loss: 0.0131 - val_fn: 12.0000 - val_fp: 141.0000 - val_tn: 56745.0000 - val_tp: 63.0000 - val_precision: 0.3088 - val_recall: 0.8400 - val_accuracy: 8.2513e-04\n",
      "Epoch 30/100\n",
      "227846/227846 - 1s - loss: 0.1630 - fn: 36.0000 - fp: 2507.0000 - tn: 224922.0000 - tp: 381.0000 - precision: 0.1319 - recall: 0.9137 - accuracy: 0.2476 - val_loss: 0.0106 - val_fn: 18.0000 - val_fp: 14.0000 - val_tn: 56872.0000 - val_tp: 57.0000 - val_precision: 0.8028 - val_recall: 0.7600 - val_accuracy: 5.9690e-04\n",
      "Epoch 31/100\n",
      "227846/227846 - 1s - loss: 0.1480 - fn: 33.0000 - fp: 2075.0000 - tn: 225354.0000 - tp: 384.0000 - precision: 0.1562 - recall: 0.9209 - accuracy: 0.1538 - val_loss: 0.0180 - val_fn: 12.0000 - val_fp: 192.0000 - val_tn: 56694.0000 - val_tp: 63.0000 - val_precision: 0.2471 - val_recall: 0.8400 - val_accuracy: 0.0026\n",
      "Epoch 32/100\n",
      "227846/227846 - 1s - loss: 0.1425 - fn: 26.0000 - fp: 2099.0000 - tn: 225330.0000 - tp: 391.0000 - precision: 0.1570 - recall: 0.9376 - accuracy: 0.2272 - val_loss: 0.0156 - val_fn: 12.0000 - val_fp: 149.0000 - val_tn: 56737.0000 - val_tp: 63.0000 - val_precision: 0.2972 - val_recall: 0.8400 - val_accuracy: 9.6557e-04\n",
      "Epoch 33/100\n",
      "227846/227846 - 1s - loss: 0.1383 - fn: 35.0000 - fp: 2548.0000 - tn: 224881.0000 - tp: 382.0000 - precision: 0.1304 - recall: 0.9161 - accuracy: 0.2423 - val_loss: 0.0459 - val_fn: 11.0000 - val_fp: 160.0000 - val_tn: 56726.0000 - val_tp: 64.0000 - val_precision: 0.2857 - val_recall: 0.8533 - val_accuracy: 0.0082\n",
      "Epoch 34/100\n",
      "227846/227846 - 1s - loss: 0.1051 - fn: 22.0000 - fp: 2473.0000 - tn: 224956.0000 - tp: 395.0000 - precision: 0.1377 - recall: 0.9472 - accuracy: 0.4169 - val_loss: 0.0172 - val_fn: 13.0000 - val_fp: 81.0000 - val_tn: 56805.0000 - val_tp: 62.0000 - val_precision: 0.4336 - val_recall: 0.8267 - val_accuracy: 0.3971\n",
      "Epoch 35/100\n",
      "227846/227846 - 1s - loss: 0.1101 - fn: 24.0000 - fp: 2873.0000 - tn: 224556.0000 - tp: 393.0000 - precision: 0.1203 - recall: 0.9424 - accuracy: 0.4788 - val_loss: 0.0138 - val_fn: 12.0000 - val_fp: 130.0000 - val_tn: 56756.0000 - val_tp: 63.0000 - val_precision: 0.3264 - val_recall: 0.8400 - val_accuracy: 0.4155\n",
      "Epoch 36/100\n",
      "227846/227846 - 1s - loss: 0.1249 - fn: 27.0000 - fp: 1828.0000 - tn: 225601.0000 - tp: 390.0000 - precision: 0.1758 - recall: 0.9353 - accuracy: 0.3190 - val_loss: 0.0156 - val_fn: 12.0000 - val_fp: 148.0000 - val_tn: 56738.0000 - val_tp: 63.0000 - val_precision: 0.2986 - val_recall: 0.8400 - val_accuracy: 8.7779e-04\n",
      "Epoch 37/100\n",
      "227846/227846 - 1s - loss: 0.1610 - fn: 31.0000 - fp: 3654.0000 - tn: 223775.0000 - tp: 386.0000 - precision: 0.0955 - recall: 0.9257 - accuracy: 0.3948 - val_loss: 0.0284 - val_fn: 13.0000 - val_fp: 129.0000 - val_tn: 56757.0000 - val_tp: 62.0000 - val_precision: 0.3246 - val_recall: 0.8267 - val_accuracy: 9.4802e-04\n",
      "Epoch 38/100\n",
      "227846/227846 - 1s - loss: 0.1175 - fn: 31.0000 - fp: 2348.0000 - tn: 225081.0000 - tp: 386.0000 - precision: 0.1412 - recall: 0.9257 - accuracy: 0.3369 - val_loss: 0.0269 - val_fn: 12.0000 - val_fp: 180.0000 - val_tn: 56706.0000 - val_tp: 63.0000 - val_precision: 0.2593 - val_recall: 0.8400 - val_accuracy: 8.7779e-04\n",
      "Epoch 39/100\n",
      "227846/227846 - 1s - loss: 0.1208 - fn: 30.0000 - fp: 2040.0000 - tn: 225389.0000 - tp: 387.0000 - precision: 0.1595 - recall: 0.9281 - accuracy: 0.3802 - val_loss: 0.0680 - val_fn: 8.0000 - val_fp: 1233.0000 - val_tn: 55653.0000 - val_tp: 67.0000 - val_precision: 0.0515 - val_recall: 0.8933 - val_accuracy: 8.9535e-04\n",
      "Epoch 40/100\n",
      "227846/227846 - 1s - loss: 0.1561 - fn: 30.0000 - fp: 2866.0000 - tn: 224563.0000 - tp: 387.0000 - precision: 0.1190 - recall: 0.9281 - accuracy: 0.3226 - val_loss: 0.0513 - val_fn: 9.0000 - val_fp: 801.0000 - val_tn: 56085.0000 - val_tp: 66.0000 - val_precision: 0.0761 - val_recall: 0.8800 - val_accuracy: 0.0807\n",
      "Epoch 41/100\n",
      "227846/227846 - 1s - loss: 0.1334 - fn: 24.0000 - fp: 2635.0000 - tn: 224794.0000 - tp: 393.0000 - precision: 0.1298 - recall: 0.9424 - accuracy: 0.3530 - val_loss: 0.0064 - val_fn: 13.0000 - val_fp: 58.0000 - val_tn: 56828.0000 - val_tp: 62.0000 - val_precision: 0.5167 - val_recall: 0.8267 - val_accuracy: 0.1238\n",
      "Epoch 42/100\n",
      "227846/227846 - 1s - loss: 0.1113 - fn: 25.0000 - fp: 2165.0000 - tn: 225264.0000 - tp: 392.0000 - precision: 0.1533 - recall: 0.9400 - accuracy: 0.5041 - val_loss: 0.0243 - val_fn: 13.0000 - val_fp: 112.0000 - val_tn: 56774.0000 - val_tp: 62.0000 - val_precision: 0.3563 - val_recall: 0.8267 - val_accuracy: 0.0019\n",
      "Epoch 43/100\n",
      "227846/227846 - 1s - loss: 0.1269 - fn: 28.0000 - fp: 2160.0000 - tn: 225269.0000 - tp: 389.0000 - precision: 0.1526 - recall: 0.9329 - accuracy: 0.4149 - val_loss: 0.0262 - val_fn: 11.0000 - val_fp: 139.0000 - val_tn: 56747.0000 - val_tp: 64.0000 - val_precision: 0.3153 - val_recall: 0.8533 - val_accuracy: 8.2513e-04\n",
      "Epoch 44/100\n",
      "227846/227846 - 1s - loss: 0.1490 - fn: 32.0000 - fp: 3062.0000 - tn: 224367.0000 - tp: 385.0000 - precision: 0.1117 - recall: 0.9233 - accuracy: 0.4477 - val_loss: 0.0218 - val_fn: 14.0000 - val_fp: 46.0000 - val_tn: 56840.0000 - val_tp: 61.0000 - val_precision: 0.5701 - val_recall: 0.8133 - val_accuracy: 9.4802e-04\n",
      "Epoch 45/100\n",
      "227846/227846 - 1s - loss: 0.1496 - fn: 35.0000 - fp: 2504.0000 - tn: 224925.0000 - tp: 382.0000 - precision: 0.1324 - recall: 0.9161 - accuracy: 0.3594 - val_loss: 0.0116 - val_fn: 12.0000 - val_fp: 97.0000 - val_tn: 56789.0000 - val_tp: 63.0000 - val_precision: 0.3938 - val_recall: 0.8400 - val_accuracy: 0.4853\n",
      "Epoch 46/100\n",
      "227846/227846 - 1s - loss: 0.1822 - fn: 36.0000 - fp: 2989.0000 - tn: 224440.0000 - tp: 381.0000 - precision: 0.1131 - recall: 0.9137 - accuracy: 0.5030 - val_loss: 0.0517 - val_fn: 9.0000 - val_fp: 474.0000 - val_tn: 56412.0000 - val_tp: 66.0000 - val_precision: 0.1222 - val_recall: 0.8800 - val_accuracy: 0.6465\n",
      "Epoch 47/100\n",
      "227846/227846 - 1s - loss: 0.1461 - fn: 35.0000 - fp: 2685.0000 - tn: 224744.0000 - tp: 382.0000 - precision: 0.1246 - recall: 0.9161 - accuracy: 0.5740 - val_loss: 0.0136 - val_fn: 12.0000 - val_fp: 138.0000 - val_tn: 56748.0000 - val_tp: 63.0000 - val_precision: 0.3134 - val_recall: 0.8400 - val_accuracy: 0.6169\n",
      "Epoch 48/100\n",
      "227846/227846 - 1s - loss: 0.1428 - fn: 32.0000 - fp: 3632.0000 - tn: 223797.0000 - tp: 385.0000 - precision: 0.0958 - recall: 0.9233 - accuracy: 0.7002 - val_loss: 0.0171 - val_fn: 10.0000 - val_fp: 368.0000 - val_tn: 56518.0000 - val_tp: 65.0000 - val_precision: 0.1501 - val_recall: 0.8667 - val_accuracy: 0.8865\n",
      "Epoch 49/100\n",
      "227846/227846 - 1s - loss: 0.1244 - fn: 26.0000 - fp: 2727.0000 - tn: 224702.0000 - tp: 391.0000 - precision: 0.1254 - recall: 0.9376 - accuracy: 0.6249 - val_loss: 0.0117 - val_fn: 14.0000 - val_fp: 72.0000 - val_tn: 56814.0000 - val_tp: 61.0000 - val_precision: 0.4586 - val_recall: 0.8133 - val_accuracy: 0.9873\n",
      "Epoch 50/100\n",
      "227846/227846 - 1s - loss: 0.2706 - fn: 35.0000 - fp: 2950.0000 - tn: 224479.0000 - tp: 382.0000 - precision: 0.1146 - recall: 0.9161 - accuracy: 0.1494 - val_loss: 0.0135 - val_fn: 13.0000 - val_fp: 120.0000 - val_tn: 56766.0000 - val_tp: 62.0000 - val_precision: 0.3407 - val_recall: 0.8267 - val_accuracy: 0.5642\n",
      "Epoch 51/100\n",
      "227846/227846 - 1s - loss: 0.1441 - fn: 35.0000 - fp: 2269.0000 - tn: 225160.0000 - tp: 382.0000 - precision: 0.1441 - recall: 0.9161 - accuracy: 0.2409 - val_loss: 0.0170 - val_fn: 10.0000 - val_fp: 157.0000 - val_tn: 56729.0000 - val_tp: 65.0000 - val_precision: 0.2928 - val_recall: 0.8667 - val_accuracy: 0.0105\n",
      "Epoch 52/100\n",
      "227846/227846 - 1s - loss: 0.1490 - fn: 31.0000 - fp: 2709.0000 - tn: 224720.0000 - tp: 386.0000 - precision: 0.1247 - recall: 0.9257 - accuracy: 0.5128 - val_loss: 0.0194 - val_fn: 12.0000 - val_fp: 98.0000 - val_tn: 56788.0000 - val_tp: 63.0000 - val_precision: 0.3913 - val_recall: 0.8400 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "227846/227846 - 1s - loss: 0.1471 - fn: 36.0000 - fp: 2556.0000 - tn: 224873.0000 - tp: 381.0000 - precision: 0.1297 - recall: 0.9137 - accuracy: 0.2834 - val_loss: 0.0097 - val_fn: 13.0000 - val_fp: 47.0000 - val_tn: 56839.0000 - val_tp: 62.0000 - val_precision: 0.5688 - val_recall: 0.8267 - val_accuracy: 0.4200\n",
      "Epoch 54/100\n",
      "227846/227846 - 1s - loss: 0.1264 - fn: 25.0000 - fp: 2261.0000 - tn: 225168.0000 - tp: 392.0000 - precision: 0.1478 - recall: 0.9400 - accuracy: 0.2523 - val_loss: 0.0085 - val_fn: 14.0000 - val_fp: 25.0000 - val_tn: 56861.0000 - val_tp: 61.0000 - val_precision: 0.7093 - val_recall: 0.8133 - val_accuracy: 9.8313e-04\n",
      "Epoch 55/100\n",
      "227846/227846 - 1s - loss: 0.1149 - fn: 24.0000 - fp: 1529.0000 - tn: 225900.0000 - tp: 393.0000 - precision: 0.2045 - recall: 0.9424 - accuracy: 0.2366 - val_loss: 0.0146 - val_fn: 12.0000 - val_fp: 142.0000 - val_tn: 56744.0000 - val_tp: 63.0000 - val_precision: 0.3073 - val_recall: 0.8400 - val_accuracy: 9.3046e-04\n",
      "Epoch 56/100\n",
      "227846/227846 - 1s - loss: 0.1213 - fn: 26.0000 - fp: 2237.0000 - tn: 225192.0000 - tp: 391.0000 - precision: 0.1488 - recall: 0.9376 - accuracy: 0.1866 - val_loss: 0.0131 - val_fn: 12.0000 - val_fp: 109.0000 - val_tn: 56777.0000 - val_tp: 63.0000 - val_precision: 0.3663 - val_recall: 0.8400 - val_accuracy: 9.3046e-04\n",
      "Epoch 57/100\n",
      "227846/227846 - 1s - loss: 0.1088 - fn: 24.0000 - fp: 2246.0000 - tn: 225183.0000 - tp: 393.0000 - precision: 0.1489 - recall: 0.9424 - accuracy: 0.2239 - val_loss: 0.0122 - val_fn: 12.0000 - val_fp: 134.0000 - val_tn: 56752.0000 - val_tp: 63.0000 - val_precision: 0.3198 - val_recall: 0.8400 - val_accuracy: 0.6932\n",
      "Epoch 58/100\n",
      "227846/227846 - 1s - loss: 0.1024 - fn: 22.0000 - fp: 2311.0000 - tn: 225118.0000 - tp: 395.0000 - precision: 0.1460 - recall: 0.9472 - accuracy: 0.5958 - val_loss: 0.0101 - val_fn: 13.0000 - val_fp: 118.0000 - val_tn: 56768.0000 - val_tp: 62.0000 - val_precision: 0.3444 - val_recall: 0.8267 - val_accuracy: 0.4485\n",
      "Epoch 59/100\n",
      "227846/227846 - 1s - loss: 0.0930 - fn: 13.0000 - fp: 2214.0000 - tn: 225215.0000 - tp: 404.0000 - precision: 0.1543 - recall: 0.9688 - accuracy: 0.4662 - val_loss: 0.0070 - val_fn: 16.0000 - val_fp: 11.0000 - val_tn: 56875.0000 - val_tp: 59.0000 - val_precision: 0.8429 - val_recall: 0.7867 - val_accuracy: 0.0169\n",
      "Epoch 60/100\n",
      "227846/227846 - 1s - loss: 0.1012 - fn: 23.0000 - fp: 2311.0000 - tn: 225118.0000 - tp: 394.0000 - precision: 0.1457 - recall: 0.9448 - accuracy: 0.4866 - val_loss: 0.0189 - val_fn: 10.0000 - val_fp: 243.0000 - val_tn: 56643.0000 - val_tp: 65.0000 - val_precision: 0.2110 - val_recall: 0.8667 - val_accuracy: 0.5471\n",
      "Epoch 61/100\n",
      "227846/227846 - 1s - loss: 0.1208 - fn: 25.0000 - fp: 2190.0000 - tn: 225239.0000 - tp: 392.0000 - precision: 0.1518 - recall: 0.9400 - accuracy: 0.2607 - val_loss: 0.0121 - val_fn: 11.0000 - val_fp: 115.0000 - val_tn: 56771.0000 - val_tp: 64.0000 - val_precision: 0.3575 - val_recall: 0.8533 - val_accuracy: 8.7779e-04\n",
      "Epoch 62/100\n",
      "227846/227846 - 1s - loss: 0.0848 - fn: 18.0000 - fp: 1969.0000 - tn: 225460.0000 - tp: 399.0000 - precision: 0.1685 - recall: 0.9568 - accuracy: 0.2743 - val_loss: 0.0223 - val_fn: 10.0000 - val_fp: 272.0000 - val_tn: 56614.0000 - val_tp: 65.0000 - val_precision: 0.1929 - val_recall: 0.8667 - val_accuracy: 0.1234\n",
      "Epoch 63/100\n",
      "227846/227846 - 1s - loss: 0.1183 - fn: 27.0000 - fp: 2772.0000 - tn: 224657.0000 - tp: 390.0000 - precision: 0.1233 - recall: 0.9353 - accuracy: 0.4409 - val_loss: 0.0216 - val_fn: 12.0000 - val_fp: 160.0000 - val_tn: 56726.0000 - val_tp: 63.0000 - val_precision: 0.2825 - val_recall: 0.8400 - val_accuracy: 8.6024e-04\n",
      "Epoch 64/100\n",
      "227846/227846 - 1s - loss: 0.1325 - fn: 27.0000 - fp: 1768.0000 - tn: 225661.0000 - tp: 390.0000 - precision: 0.1807 - recall: 0.9353 - accuracy: 0.2190 - val_loss: 0.0164 - val_fn: 10.0000 - val_fp: 173.0000 - val_tn: 56713.0000 - val_tp: 65.0000 - val_precision: 0.2731 - val_recall: 0.8667 - val_accuracy: 0.0106\n",
      "Epoch 65/100\n",
      "227846/227846 - 1s - loss: 0.1760 - fn: 34.0000 - fp: 2986.0000 - tn: 224443.0000 - tp: 383.0000 - precision: 0.1137 - recall: 0.9185 - accuracy: 0.3435 - val_loss: 0.0054 - val_fn: 15.0000 - val_fp: 34.0000 - val_tn: 56852.0000 - val_tp: 60.0000 - val_precision: 0.6383 - val_recall: 0.8000 - val_accuracy: 9.1291e-04\n",
      "Epoch 66/100\n",
      "227846/227846 - 1s - loss: 0.1455 - fn: 30.0000 - fp: 2232.0000 - tn: 225197.0000 - tp: 387.0000 - precision: 0.1478 - recall: 0.9281 - accuracy: 0.1683 - val_loss: 0.0086 - val_fn: 16.0000 - val_fp: 18.0000 - val_tn: 56868.0000 - val_tp: 59.0000 - val_precision: 0.7662 - val_recall: 0.7867 - val_accuracy: 9.3046e-04\n",
      "Epoch 67/100\n",
      "227846/227846 - 1s - loss: 0.1491 - fn: 37.0000 - fp: 2220.0000 - tn: 225209.0000 - tp: 380.0000 - precision: 0.1462 - recall: 0.9113 - accuracy: 0.1287 - val_loss: 0.0085 - val_fn: 13.0000 - val_fp: 56.0000 - val_tn: 56830.0000 - val_tp: 62.0000 - val_precision: 0.5254 - val_recall: 0.8267 - val_accuracy: 9.3046e-04\n",
      "Epoch 68/100\n",
      "227846/227846 - 1s - loss: 0.1400 - fn: 23.0000 - fp: 1869.0000 - tn: 225560.0000 - tp: 394.0000 - precision: 0.1741 - recall: 0.9448 - accuracy: 0.0661 - val_loss: 0.0060 - val_fn: 18.0000 - val_fp: 10.0000 - val_tn: 56876.0000 - val_tp: 57.0000 - val_precision: 0.8507 - val_recall: 0.7600 - val_accuracy: 9.6557e-04\n",
      "Epoch 69/100\n",
      "227846/227846 - 1s - loss: 0.1582 - fn: 29.0000 - fp: 1791.0000 - tn: 225638.0000 - tp: 388.0000 - precision: 0.1781 - recall: 0.9305 - accuracy: 0.1172 - val_loss: 0.0227 - val_fn: 11.0000 - val_fp: 111.0000 - val_tn: 56775.0000 - val_tp: 64.0000 - val_precision: 0.3657 - val_recall: 0.8533 - val_accuracy: 9.4802e-04\n",
      "Epoch 70/100\n",
      "227846/227846 - 1s - loss: 0.1124 - fn: 29.0000 - fp: 2100.0000 - tn: 225329.0000 - tp: 388.0000 - precision: 0.1559 - recall: 0.9305 - accuracy: 0.2366 - val_loss: 0.0171 - val_fn: 11.0000 - val_fp: 164.0000 - val_tn: 56722.0000 - val_tp: 64.0000 - val_precision: 0.2807 - val_recall: 0.8533 - val_accuracy: 0.6740\n",
      "Epoch 71/100\n",
      "227846/227846 - 1s - loss: 0.1611 - fn: 31.0000 - fp: 1917.0000 - tn: 225512.0000 - tp: 386.0000 - precision: 0.1676 - recall: 0.9257 - accuracy: 0.1381 - val_loss: 0.0251 - val_fn: 11.0000 - val_fp: 160.0000 - val_tn: 56726.0000 - val_tp: 64.0000 - val_precision: 0.2857 - val_recall: 0.8533 - val_accuracy: 9.8313e-04\n",
      "Epoch 72/100\n",
      "227846/227846 - 1s - loss: 0.1585 - fn: 32.0000 - fp: 2517.0000 - tn: 224912.0000 - tp: 385.0000 - precision: 0.1327 - recall: 0.9233 - accuracy: 0.1430 - val_loss: 0.0101 - val_fn: 12.0000 - val_fp: 101.0000 - val_tn: 56785.0000 - val_tp: 63.0000 - val_precision: 0.3841 - val_recall: 0.8400 - val_accuracy: 9.6557e-04\n",
      "Epoch 73/100\n",
      "227846/227846 - 1s - loss: 0.1437 - fn: 32.0000 - fp: 3065.0000 - tn: 224364.0000 - tp: 385.0000 - precision: 0.1116 - recall: 0.9233 - accuracy: 0.3055 - val_loss: 0.0133 - val_fn: 12.0000 - val_fp: 101.0000 - val_tn: 56785.0000 - val_tp: 63.0000 - val_precision: 0.3841 - val_recall: 0.8400 - val_accuracy: 0.0650\n",
      "Epoch 74/100\n",
      "227846/227846 - 1s - loss: 0.1423 - fn: 28.0000 - fp: 3044.0000 - tn: 224385.0000 - tp: 389.0000 - precision: 0.1133 - recall: 0.9329 - accuracy: 0.3401 - val_loss: 0.0075 - val_fn: 11.0000 - val_fp: 127.0000 - val_tn: 56759.0000 - val_tp: 64.0000 - val_precision: 0.3351 - val_recall: 0.8533 - val_accuracy: 7.9001e-04\n",
      "Epoch 75/100\n",
      "227846/227846 - 1s - loss: 0.1591 - fn: 32.0000 - fp: 2590.0000 - tn: 224839.0000 - tp: 385.0000 - precision: 0.1294 - recall: 0.9233 - accuracy: 0.2828 - val_loss: 0.0324 - val_fn: 10.0000 - val_fp: 267.0000 - val_tn: 56619.0000 - val_tp: 65.0000 - val_precision: 0.1958 - val_recall: 0.8667 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "227846/227846 - 1s - loss: 0.2408 - fn: 38.0000 - fp: 3987.0000 - tn: 223442.0000 - tp: 379.0000 - precision: 0.0868 - recall: 0.9089 - accuracy: 0.2200 - val_loss: 0.0152 - val_fn: 13.0000 - val_fp: 71.0000 - val_tn: 56815.0000 - val_tp: 62.0000 - val_precision: 0.4662 - val_recall: 0.8267 - val_accuracy: 0.0010\n",
      "Epoch 77/100\n",
      "227846/227846 - 1s - loss: 0.1500 - fn: 32.0000 - fp: 2924.0000 - tn: 224505.0000 - tp: 385.0000 - precision: 0.1163 - recall: 0.9233 - accuracy: 0.1639 - val_loss: 0.0085 - val_fn: 18.0000 - val_fp: 10.0000 - val_tn: 56876.0000 - val_tp: 57.0000 - val_precision: 0.8507 - val_recall: 0.7600 - val_accuracy: 8.9535e-04\n",
      "Epoch 78/100\n",
      "227846/227846 - 1s - loss: 0.1238 - fn: 27.0000 - fp: 1542.0000 - tn: 225887.0000 - tp: 390.0000 - precision: 0.2019 - recall: 0.9353 - accuracy: 0.0964 - val_loss: 0.0077 - val_fn: 13.0000 - val_fp: 118.0000 - val_tn: 56768.0000 - val_tp: 62.0000 - val_precision: 0.3444 - val_recall: 0.8267 - val_accuracy: 9.1291e-04\n",
      "Epoch 79/100\n",
      "227846/227846 - 1s - loss: 0.1768 - fn: 34.0000 - fp: 3850.0000 - tn: 223579.0000 - tp: 383.0000 - precision: 0.0905 - recall: 0.9185 - accuracy: 0.1659 - val_loss: 0.0219 - val_fn: 10.0000 - val_fp: 186.0000 - val_tn: 56700.0000 - val_tp: 65.0000 - val_precision: 0.2590 - val_recall: 0.8667 - val_accuracy: 9.6557e-04\n",
      "Epoch 80/100\n",
      "227846/227846 - 1s - loss: 0.1383 - fn: 28.0000 - fp: 2793.0000 - tn: 224636.0000 - tp: 389.0000 - precision: 0.1223 - recall: 0.9329 - accuracy: 0.0052 - val_loss: 0.0132 - val_fn: 13.0000 - val_fp: 89.0000 - val_tn: 56797.0000 - val_tp: 62.0000 - val_precision: 0.4106 - val_recall: 0.8267 - val_accuracy: 9.4802e-04\n",
      "Epoch 81/100\n",
      "227846/227846 - 1s - loss: 0.1817 - fn: 36.0000 - fp: 5262.0000 - tn: 222167.0000 - tp: 381.0000 - precision: 0.0675 - recall: 0.9137 - accuracy: 0.0736 - val_loss: 0.0122 - val_fn: 16.0000 - val_fp: 22.0000 - val_tn: 56864.0000 - val_tp: 59.0000 - val_precision: 0.7284 - val_recall: 0.7867 - val_accuracy: 6.3201e-04\n",
      "Epoch 82/100\n",
      "227846/227846 - 1s - loss: 0.1323 - fn: 33.0000 - fp: 2001.0000 - tn: 225428.0000 - tp: 384.0000 - precision: 0.1610 - recall: 0.9209 - accuracy: 0.0405 - val_loss: 0.0075 - val_fn: 14.0000 - val_fp: 98.0000 - val_tn: 56788.0000 - val_tp: 61.0000 - val_precision: 0.3836 - val_recall: 0.8133 - val_accuracy: 9.1291e-04\n",
      "Epoch 83/100\n",
      "227846/227846 - 1s - loss: 0.1903 - fn: 32.0000 - fp: 2889.0000 - tn: 224540.0000 - tp: 385.0000 - precision: 0.1176 - recall: 0.9233 - accuracy: 0.0131 - val_loss: 0.0145 - val_fn: 14.0000 - val_fp: 42.0000 - val_tn: 56844.0000 - val_tp: 61.0000 - val_precision: 0.5922 - val_recall: 0.8133 - val_accuracy: 9.8313e-04\n",
      "Epoch 84/100\n",
      "227846/227846 - 1s - loss: 0.1426 - fn: 28.0000 - fp: 2068.0000 - tn: 225361.0000 - tp: 389.0000 - precision: 0.1583 - recall: 0.9329 - accuracy: 0.0730 - val_loss: 0.0188 - val_fn: 13.0000 - val_fp: 135.0000 - val_tn: 56751.0000 - val_tp: 62.0000 - val_precision: 0.3147 - val_recall: 0.8267 - val_accuracy: 9.8313e-04\n",
      "Epoch 85/100\n",
      "227846/227846 - 1s - loss: 0.1257 - fn: 31.0000 - fp: 1714.0000 - tn: 225715.0000 - tp: 386.0000 - precision: 0.1838 - recall: 0.9257 - accuracy: 0.0453 - val_loss: 0.0137 - val_fn: 11.0000 - val_fp: 188.0000 - val_tn: 56698.0000 - val_tp: 64.0000 - val_precision: 0.2540 - val_recall: 0.8533 - val_accuracy: 8.6024e-04\n",
      "Epoch 86/100\n",
      "227846/227846 - 1s - loss: 0.1129 - fn: 24.0000 - fp: 2500.0000 - tn: 224929.0000 - tp: 393.0000 - precision: 0.1358 - recall: 0.9424 - accuracy: 0.0059 - val_loss: 0.0908 - val_fn: 10.0000 - val_fp: 388.0000 - val_tn: 56498.0000 - val_tp: 65.0000 - val_precision: 0.1435 - val_recall: 0.8667 - val_accuracy: 8.7779e-04\n",
      "Epoch 87/100\n",
      "227846/227846 - 1s - loss: 0.1348 - fn: 28.0000 - fp: 1943.0000 - tn: 225486.0000 - tp: 389.0000 - precision: 0.1668 - recall: 0.9329 - accuracy: 9.1729e-04 - val_loss: 0.0202 - val_fn: 10.0000 - val_fp: 188.0000 - val_tn: 56698.0000 - val_tp: 65.0000 - val_precision: 0.2569 - val_recall: 0.8667 - val_accuracy: 9.6557e-04\n",
      "Epoch 88/100\n",
      "227846/227846 - 1s - loss: 0.1197 - fn: 24.0000 - fp: 2019.0000 - tn: 225410.0000 - tp: 393.0000 - precision: 0.1629 - recall: 0.9424 - accuracy: 0.0011 - val_loss: 0.0273 - val_fn: 14.0000 - val_fp: 33.0000 - val_tn: 56853.0000 - val_tp: 61.0000 - val_precision: 0.6489 - val_recall: 0.8133 - val_accuracy: 7.9001e-04\n",
      "Epoch 89/100\n",
      "227846/227846 - 1s - loss: 0.1194 - fn: 23.0000 - fp: 2732.0000 - tn: 224697.0000 - tp: 394.0000 - precision: 0.1260 - recall: 0.9448 - accuracy: 9.1729e-04 - val_loss: 0.0149 - val_fn: 16.0000 - val_fp: 43.0000 - val_tn: 56843.0000 - val_tp: 59.0000 - val_precision: 0.5784 - val_recall: 0.7867 - val_accuracy: 7.9001e-04\n",
      "Epoch 90/100\n",
      "227846/227846 - 1s - loss: 0.1148 - fn: 26.0000 - fp: 2124.0000 - tn: 225305.0000 - tp: 391.0000 - precision: 0.1555 - recall: 0.9376 - accuracy: 9.4801e-04 - val_loss: 0.0198 - val_fn: 10.0000 - val_fp: 180.0000 - val_tn: 56706.0000 - val_tp: 65.0000 - val_precision: 0.2653 - val_recall: 0.8667 - val_accuracy: 8.2513e-04\n",
      "Epoch 91/100\n",
      "227846/227846 - 1s - loss: 0.1334 - fn: 26.0000 - fp: 3230.0000 - tn: 224199.0000 - tp: 391.0000 - precision: 0.1080 - recall: 0.9376 - accuracy: 8.5584e-04 - val_loss: 0.0071 - val_fn: 18.0000 - val_fp: 15.0000 - val_tn: 56871.0000 - val_tp: 57.0000 - val_precision: 0.7917 - val_recall: 0.7600 - val_accuracy: 2.6334e-04\n",
      "Epoch 92/100\n",
      "227846/227846 - 1s - loss: 0.1382 - fn: 30.0000 - fp: 2578.0000 - tn: 224851.0000 - tp: 387.0000 - precision: 0.1305 - recall: 0.9281 - accuracy: 0.0012 - val_loss: 0.0589 - val_fn: 9.0000 - val_fp: 308.0000 - val_tn: 56578.0000 - val_tp: 66.0000 - val_precision: 0.1765 - val_recall: 0.8800 - val_accuracy: 9.3046e-04\n",
      "Epoch 93/100\n",
      "227846/227846 - 1s - loss: 0.1129 - fn: 27.0000 - fp: 2141.0000 - tn: 225288.0000 - tp: 390.0000 - precision: 0.1541 - recall: 0.9353 - accuracy: 9.8751e-04 - val_loss: 0.0100 - val_fn: 12.0000 - val_fp: 86.0000 - val_tn: 56800.0000 - val_tp: 63.0000 - val_precision: 0.4228 - val_recall: 0.8400 - val_accuracy: 7.1979e-04\n",
      "Epoch 94/100\n",
      "227846/227846 - 1s - loss: 0.1027 - fn: 18.0000 - fp: 2936.0000 - tn: 224493.0000 - tp: 399.0000 - precision: 0.1196 - recall: 0.9568 - accuracy: 9.0412e-04 - val_loss: 0.0043 - val_fn: 18.0000 - val_fp: 23.0000 - val_tn: 56863.0000 - val_tp: 57.0000 - val_precision: 0.7125 - val_recall: 0.7600 - val_accuracy: 4.5645e-04\n",
      "Epoch 95/100\n",
      "227846/227846 - 1s - loss: 0.1934 - fn: 36.0000 - fp: 3178.0000 - tn: 224251.0000 - tp: 381.0000 - precision: 0.1071 - recall: 0.9137 - accuracy: 0.0030 - val_loss: 0.0187 - val_fn: 13.0000 - val_fp: 132.0000 - val_tn: 56754.0000 - val_tp: 62.0000 - val_precision: 0.3196 - val_recall: 0.8267 - val_accuracy: 7.9001e-04\n",
      "Epoch 96/100\n",
      "227846/227846 - 1s - loss: 0.1152 - fn: 20.0000 - fp: 2039.0000 - tn: 225390.0000 - tp: 397.0000 - precision: 0.1630 - recall: 0.9520 - accuracy: 0.0076 - val_loss: 0.0099 - val_fn: 13.0000 - val_fp: 56.0000 - val_tn: 56830.0000 - val_tp: 62.0000 - val_precision: 0.5254 - val_recall: 0.8267 - val_accuracy: 3.3356e-04\n",
      "Epoch 97/100\n",
      "227846/227846 - 1s - loss: 0.1275 - fn: 25.0000 - fp: 2630.0000 - tn: 224799.0000 - tp: 392.0000 - precision: 0.1297 - recall: 0.9400 - accuracy: 5.2667e-04 - val_loss: 0.0094 - val_fn: 15.0000 - val_fp: 19.0000 - val_tn: 56867.0000 - val_tp: 60.0000 - val_precision: 0.7595 - val_recall: 0.8000 - val_accuracy: 7.0223e-05\n",
      "Epoch 98/100\n",
      "227846/227846 - 1s - loss: 0.1647 - fn: 31.0000 - fp: 2622.0000 - tn: 224807.0000 - tp: 386.0000 - precision: 0.1283 - recall: 0.9257 - accuracy: 0.0022 - val_loss: 0.1072 - val_fn: 11.0000 - val_fp: 152.0000 - val_tn: 56734.0000 - val_tp: 64.0000 - val_precision: 0.2963 - val_recall: 0.8533 - val_accuracy: 8.2513e-04\n",
      "Epoch 99/100\n",
      "227846/227846 - 1s - loss: 0.1994 - fn: 42.0000 - fp: 3884.0000 - tn: 223545.0000 - tp: 375.0000 - precision: 0.0880 - recall: 0.8993 - accuracy: 8.6901e-04 - val_loss: 0.0146 - val_fn: 13.0000 - val_fp: 128.0000 - val_tn: 56758.0000 - val_tp: 62.0000 - val_precision: 0.3263 - val_recall: 0.8267 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "227846/227846 - 1s - loss: 0.2144 - fn: 38.0000 - fp: 4907.0000 - tn: 222522.0000 - tp: 379.0000 - precision: 0.0717 - recall: 0.9089 - accuracy: 0.0516 - val_loss: 0.0065 - val_fn: 18.0000 - val_fp: 34.0000 - val_tn: 56852.0000 - val_tp: 57.0000 - val_precision: 0.6264 - val_recall: 0.7600 - val_accuracy: 8.6024e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7effc5743a20>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [keras.metrics.FalseNegatives(name='fn'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.TrueNegatives(name='tn'),\n",
    "           keras.metrics.TruePositives(name='tp'),\n",
    "           keras.metrics.Precision(name='precision'),\n",
    "           keras.metrics.Recall(name='recall'),\n",
    "           keras.metrics.Accuracy(name='accuracy')]\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-2),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=metrics)\n",
    "\n",
    "#callbacks = [keras.callbacks.ModelCheckpoint('fraud_model_at_epoch_{epoch}.h5')]\n",
    "class_weight = {0: 1, 1: 200}\n",
    "\n",
    "model.fit(train_features, train_targets,\n",
    "          batch_size=4096, epochs=100, verbose=2, validation_data=(test_features, test_targets), class_weight=class_weight)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Credit Card Fraud.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
