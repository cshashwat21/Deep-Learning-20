{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qNZkm1B_Wb45"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjZwvoKp8dmg"
   },
   "outputs": [],
   "source": [
    "matplotlib_is_available = True\n",
    "try:\n",
    "  from matplotlib import pyplot as plt\n",
    "except ImportError:\n",
    "  print(\"Will skip plotting; matplotlib is not available.\")\n",
    "  matplotlib_is_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAGUGWRH8feP"
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "E62xxKni8mxm",
    "outputId": "d59cdec9-9164-4beb-9a06-af9d12a2ae1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Only 4 moments]\n"
     ]
    }
   ],
   "source": [
    "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))\n",
    "\n",
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sVupENlDgR7w",
    "outputId": "4e702cc2-908e-427b-adf5-8891f3199591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnfunrPq8rGo"
   },
   "outputs": [],
   "source": [
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZYF3WKW8y0j"
   },
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final\n",
    "\n",
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rztDihdB88s5",
    "outputId": "825cd4e7-84f6-4e07-b9f5-52a330f3377c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.5951094031333923 real_err, 0.7776383757591248 fake_err) G (0.6168729066848755 err); Real Dist ([4.004367720700801, 1.2229609962307844]),  Fake Dist ([-0.17219518375396728, 0.03572361705978872]) \n",
      "Epoch 100: D (0.64740389585495 real_err, 0.7406501173973083 fake_err) G (0.6487125754356384 err); Real Dist ([4.100630064234138, 1.2317097827418393]),  Fake Dist ([3.614851688146591, 0.9228730221200678]) \n",
      "Epoch 200: D (0.6963575482368469 real_err, 0.6931712627410889 fake_err) G (0.6921908855438232 err); Real Dist ([3.9321411757469176, 1.2637224880266655]),  Fake Dist ([3.6952185081243516, 1.1815792040038182]) \n",
      "Epoch 300: D (0.6931514739990234 real_err, 0.6931506395339966 fake_err) G (0.6931406259536743 err); Real Dist ([4.05600187560916, 1.2141860175821795]),  Fake Dist ([4.105634417533874, 1.053630790386789]) \n",
      "Epoch 400: D (0.6931242942810059 real_err, 0.6931679248809814 fake_err) G (0.6931235790252686 err); Real Dist ([3.997502566218376, 1.2241414314926702]),  Fake Dist ([4.121275189876556, 1.0640215853988428]) \n",
      "Epoch 500: D (0.6931389570236206 real_err, 0.6931511163711548 fake_err) G (0.6931395530700684 err); Real Dist ([4.057018275737763, 1.242057576577991]),  Fake Dist ([4.165964872837066, 1.0320671609422802]) \n",
      "Epoch 600: D (0.6931184530258179 real_err, 0.6931791305541992 fake_err) G (0.6931279897689819 err); Real Dist ([3.9888572654128076, 1.2900374843731444]),  Fake Dist ([3.8471671763658524, 1.2725241500233018]) \n",
      "Epoch 700: D (0.6933163404464722 real_err, 0.6931718587875366 fake_err) G (0.6931698322296143 err); Real Dist ([4.106064981400967, 1.19420538162341]),  Fake Dist ([4.018044856309891, 1.1950164275313617]) \n",
      "Epoch 800: D (0.6931313276290894 real_err, 0.6932440996170044 fake_err) G (0.6932692527770996 err); Real Dist ([3.9317836684584617, 1.3219165283099812]),  Fake Dist ([3.957598630905151, 1.264746288105462]) \n",
      "Epoch 900: D (0.6936237812042236 real_err, 0.6931782960891724 fake_err) G (0.6931017637252808 err); Real Dist ([3.955987943530083, 1.262094244623461]),  Fake Dist ([3.9666215205192565, 1.2731512560531861]) \n",
      "Epoch 1000: D (0.6931536197662354 real_err, 0.6930938959121704 fake_err) G (0.6931133270263672 err); Real Dist ([3.9456979763507842, 1.2364744221174324]),  Fake Dist ([4.068839848995209, 1.259114438793866]) \n",
      "Epoch 1100: D (0.693143367767334 real_err, 0.6931266784667969 fake_err) G (0.6931434869766235 err); Real Dist ([3.9324104574322702, 1.1747577096444846]),  Fake Dist ([4.145273963451386, 1.1850618417820677]) \n",
      "Epoch 1200: D (0.6931370496749878 real_err, 0.6930595636367798 fake_err) G (0.6931365728378296 err); Real Dist ([3.9522595627307893, 1.2449748134533145]),  Fake Dist ([4.094032925844193, 1.209999142559502]) \n",
      "Epoch 1300: D (0.6931447982788086 real_err, 0.6931469440460205 fake_err) G (0.6931430101394653 err); Real Dist ([4.007302664637566, 1.2115087029996272]),  Fake Dist ([4.016342876672745, 1.282196189046215]) \n",
      "Epoch 1400: D (0.6931382417678833 real_err, 0.6931564807891846 fake_err) G (0.6931453943252563 err); Real Dist ([3.9628938163518908, 1.2207408930892862]),  Fake Dist ([4.111293338298798, 1.2299981557572457]) \n",
      "Epoch 1500: D (0.6931414604187012 real_err, 0.6931557655334473 fake_err) G (0.6931449174880981 err); Real Dist ([4.015341751158237, 1.2745715325858364]),  Fake Dist ([4.064352474689484, 1.215672130671671]) \n",
      "Epoch 1600: D (0.693144679069519 real_err, 0.6931169033050537 fake_err) G (0.693142294883728 err); Real Dist ([4.055799456000328, 1.2681183502011772]),  Fake Dist ([4.285957469940185, 1.126805602014373]) \n",
      "Epoch 1700: D (0.6931408643722534 real_err, 0.6931536197662354 fake_err) G (0.6931403875350952 err); Real Dist ([4.0904797084331515, 1.2602226891777368]),  Fake Dist ([4.149380565881729, 1.2087509960021428]) \n",
      "Epoch 1800: D (0.6931358575820923 real_err, 0.6931562423706055 fake_err) G (0.693143367767334 err); Real Dist ([4.026299284398556, 1.1818768761104732]),  Fake Dist ([4.0703872330188755, 1.221687824933746]) \n",
      "Epoch 1900: D (0.693139910697937 real_err, 0.6931350231170654 fake_err) G (0.693148136138916 err); Real Dist ([3.9802236322164535, 1.1886615239180247]),  Fake Dist ([4.151255230665207, 1.1896645522969487]) \n",
      "Epoch 2000: D (0.6931679248809814 real_err, 0.6931393146514893 fake_err) G (0.6931452751159668 err); Real Dist ([4.033256618767977, 1.2816354015623979]),  Fake Dist ([4.080357850074768, 1.2237163766582042]) \n",
      "Epoch 2100: D (0.6931488513946533 real_err, 0.6931494474411011 fake_err) G (0.6931425333023071 err); Real Dist ([3.982728909254074, 1.2274803595925015]),  Fake Dist ([4.154956388473511, 1.249491151594288]) \n",
      "Epoch 2200: D (0.6931759119033813 real_err, 0.6931408643722534 fake_err) G (0.6931483745574951 err); Real Dist ([3.961603309214115, 1.2171973626014612]),  Fake Dist ([4.004064281463623, 1.2823819164104473]) \n",
      "Epoch 2300: D (0.6931436061859131 real_err, 0.6931471824645996 fake_err) G (0.6931338310241699 err); Real Dist ([3.9603426003456117, 1.2025085371082826]),  Fake Dist ([4.102629518270493, 1.2344118684156453]) \n",
      "Epoch 2400: D (0.6931626796722412 real_err, 0.6931456327438354 fake_err) G (0.6931475400924683 err); Real Dist ([3.9577135158777237, 1.2783916168960832]),  Fake Dist ([4.118910243034363, 1.2466383493673978]) \n",
      "Epoch 2500: D (0.6931463479995728 real_err, 0.6931463479995728 fake_err) G (0.6931438446044922 err); Real Dist ([3.9517237066477535, 1.2307011719038372]),  Fake Dist ([4.151775716543198, 1.1973383050672903]) \n",
      "Epoch 2600: D (0.6931463479995728 real_err, 0.6931504011154175 fake_err) G (0.6931502819061279 err); Real Dist ([4.029353726625443, 1.2437383451886646]),  Fake Dist ([4.001456014633178, 1.2879188844503622]) \n",
      "Epoch 2700: D (0.6931465864181519 real_err, 0.6931387186050415 fake_err) G (0.6931490898132324 err); Real Dist ([4.02664198088646, 1.215967686413932]),  Fake Dist ([4.209504632949829, 1.1992712801838012]) \n",
      "Epoch 2800: D (0.6931467056274414 real_err, 0.6931374073028564 fake_err) G (0.6931490898132324 err); Real Dist ([3.9371527267992494, 1.264036138324186]),  Fake Dist ([4.05129864025116, 1.2656222043830916]) \n",
      "Epoch 2900: D (0.6931440830230713 real_err, 0.6931467056274414 fake_err) G (0.6931514739990234 err); Real Dist ([4.1147635293006894, 1.237353064325115]),  Fake Dist ([4.036980350971222, 1.2959363309114735]) \n",
      "Epoch 3000: D (0.6931636333465576 real_err, 0.693148136138916 fake_err) G (0.6931434869766235 err); Real Dist ([4.065104311347008, 1.1782677666824908]),  Fake Dist ([4.133110891580582, 1.251850695506682]) \n",
      "Epoch 3100: D (0.6931493282318115 real_err, 0.6931406259536743 fake_err) G (0.6931495666503906 err); Real Dist ([3.8979087716341017, 1.2603314814730633]),  Fake Dist ([4.196774498462677, 1.201596088978406]) \n",
      "Epoch 3200: D (0.6931593418121338 real_err, 0.6931455135345459 fake_err) G (0.693145751953125 err); Real Dist ([3.945671475112438, 1.174004765704449]),  Fake Dist ([3.927025831460953, 1.306067367749641]) \n",
      "Epoch 3300: D (0.6931424140930176 real_err, 0.6931506395339966 fake_err) G (0.6931445598602295 err); Real Dist ([3.8972005007267, 1.2383278295488975]),  Fake Dist ([4.087625071763992, 1.2202011427620023]) \n",
      "Epoch 3400: D (0.6931504011154175 real_err, 0.6931483745574951 fake_err) G (0.6931462287902832 err); Real Dist ([3.9868727722615005, 1.2457746298678742]),  Fake Dist ([4.022662777900695, 1.314904409464579]) \n",
      "Epoch 3500: D (0.6931461095809937 real_err, 0.693149209022522 fake_err) G (0.6931483745574951 err); Real Dist ([3.9549037794619797, 1.2462580454742618]),  Fake Dist ([4.0316393814086915, 1.257880019392419]) \n",
      "Epoch 3600: D (0.6931494474411011 real_err, 0.6931480169296265 fake_err) G (0.6931464672088623 err); Real Dist ([3.9535778798013927, 1.3156620212008965]),  Fake Dist ([4.109502058744431, 1.236977222621261]) \n",
      "Epoch 3700: D (0.6931451559066772 real_err, 0.6931473016738892 fake_err) G (0.6931469440460205 err); Real Dist ([3.9903591778576373, 1.287035695727503]),  Fake Dist ([4.007139853477478, 1.2835797416031947]) \n",
      "Epoch 3800: D (0.6931401491165161 real_err, 0.6931484937667847 fake_err) G (0.6931440830230713 err); Real Dist ([3.9229513331055643, 1.1702092357677059]),  Fake Dist ([4.165005306482315, 1.2574410138452077]) \n",
      "Epoch 3900: D (0.6931494474411011 real_err, 0.693148136138916 fake_err) G (0.6931458711624146 err); Real Dist ([3.9632422080636025, 1.2536891121167717]),  Fake Dist ([4.113983023166656, 1.2414278648980384]) \n",
      "Epoch 4000: D (0.6931470632553101 real_err, 0.6931445598602295 fake_err) G (0.6931483745574951 err); Real Dist ([4.004083602905274, 1.28933123878416]),  Fake Dist ([4.014565188169479, 1.2999849604386848]) \n",
      "Epoch 4100: D (0.6931569576263428 real_err, 0.6931478977203369 fake_err) G (0.6931493282318115 err); Real Dist ([4.043502946734429, 1.2332084225368989]),  Fake Dist ([4.051863020658493, 1.2838007093659574]) \n",
      "Epoch 4200: D (0.6931476593017578 real_err, 0.6931478977203369 fake_err) G (0.6931476593017578 err); Real Dist ([3.9820434788912533, 1.2346346509892816]),  Fake Dist ([4.147019113063812, 1.2445996105707222]) \n",
      "Epoch 4300: D (0.6931487321853638 real_err, 0.6931464672088623 fake_err) G (0.6931471824645996 err); Real Dist ([4.022122392266989, 1.239724451862339]),  Fake Dist ([4.131012891292572, 1.259583173967656]) \n",
      "Epoch 4400: D (0.6931458711624146 real_err, 0.6931480169296265 fake_err) G (0.6931476593017578 err); Real Dist ([4.052756660384359, 1.2843644132360146]),  Fake Dist ([4.11241634273529, 1.2020016294036953]) \n",
      "Epoch 4500: D (0.6931471824645996 real_err, 0.6931493282318115 fake_err) G (0.6931447982788086 err); Real Dist ([4.041784444570541, 1.2563538800572394]),  Fake Dist ([4.150449229717255, 1.1693252262150922]) \n",
      "Epoch 4600: D (0.6931465864181519 real_err, 0.6931471824645996 fake_err) G (0.6931476593017578 err); Real Dist ([4.018754582524299, 1.2896678398487595]),  Fake Dist ([4.145305860757828, 1.2218286545695267]) \n",
      "Epoch 4700: D (0.6931483745574951 real_err, 0.6931500434875488 fake_err) G (0.6931470632553101 err); Real Dist ([4.034002655655145, 1.2719464531448395]),  Fake Dist ([4.092789886951446, 1.2326316542758966]) \n",
      "Epoch 4800: D (0.6931500434875488 real_err, 0.6931474208831787 fake_err) G (0.6931470632553101 err); Real Dist ([4.02739549523592, 1.2686174941440314]),  Fake Dist ([4.106752137899399, 1.2125226598041055]) \n",
      "Epoch 4900: D (0.6931443214416504 real_err, 0.6931452751159668 fake_err) G (0.6931571960449219 err); Real Dist ([4.038652681231499, 1.2032094838111962]),  Fake Dist ([4.132233285665512, 1.2201087159650201]) \n",
      "Plotting the generated distribution...\n",
      " Values: [5.01041841506958, 4.331883430480957, 4.3449788093566895, 1.419111967086792, 5.048518657684326, 4.970168590545654, 3.67838191986084, 5.347135066986084, 5.070769786834717, 3.200079917907715, 5.225496768951416, 1.8262439966201782, 1.6915128231048584, 5.1056904792785645, 2.845444679260254, 1.4453685283660889, 5.087372303009033, 2.3706276416778564, 3.6799211502075195, 5.071028232574463, 3.3929972648620605, 5.337376594543457, 4.5789713859558105, 5.404378890991211, 3.632420539855957, 1.270774245262146, 5.3911824226379395, 2.1990811824798584, 5.332374095916748, 5.0244903564453125, 5.361378192901611, 1.251155972480774, 4.953821659088135, 3.490640163421631, 5.386022090911865, 5.3042497634887695, 5.2599968910217285, 4.578032493591309, 5.397973537445068, 2.6403260231018066, 5.132701396942139, 1.1707987785339355, 4.426814079284668, 5.364591121673584, 5.205078125, 1.4939535856246948, 3.3865890502929688, 5.360194683074951, 3.5909061431884766, 3.926185369491577, 4.418501853942871, 4.571345806121826, 3.327218532562256, 1.1991643905639648, 2.9966039657592773, 4.0918402671813965, 4.348104000091553, 5.3303399085998535, 5.2071967124938965, 5.237538814544678, 4.047840118408203, 5.3401103019714355, 5.295717716217041, 3.47183895111084, 5.3124189376831055, 5.109776973724365, 5.0450215339660645, 2.617074966430664, 4.6673431396484375, 4.6748785972595215, 4.162393569946289, 4.419241428375244, 4.562254905700684, 1.9800587892532349, 5.402807712554932, 5.204005718231201, 3.0921666622161865, 4.883296012878418, 3.645923614501953, 5.263590335845947, 5.032842636108398, 5.3594279289245605, 5.057299613952637, 2.2779598236083984, 5.028030872344971, 4.839076995849609, 3.6137869358062744, 4.2688775062561035, 5.218710422515869, 5.324297904968262, 2.238713264465332, 5.177934646606445, 4.581624507904053, 4.954042911529541, 4.573653221130371, 5.015499591827393, 5.037415981292725, 1.693495750427246, 5.273800373077393, 5.394172191619873, 3.351597309112549, 3.331911563873291, 3.598698139190674, 3.534759044647217, 4.588655948638916, 4.327969551086426, 3.1724300384521484, 4.936999797821045, 1.2379484176635742, 5.28778600692749, 4.898904800415039, 1.1601991653442383, 4.752645969390869, 5.382030963897705, 4.344172954559326, 4.349936485290527, 1.4874444007873535, 5.314916133880615, 3.4863641262054443, 4.954747676849365, 4.422545909881592, 4.625863075256348, 4.596752643585205, 5.370090961456299, 2.789165496826172, 5.380537509918213, 4.896689414978027, 2.6054646968841553, 5.0553412437438965, 5.365170955657959, 5.31481409072876, 3.681171178817749, 1.4925365447998047, 4.728517055511475, 1.9238054752349854, 2.7613301277160645, 5.139906406402588, 1.4296854734420776, 3.5356907844543457, 4.496981143951416, 4.65501070022583, 4.8986735343933105, 5.382321834564209, 5.103810787200928, 1.5270260572433472, 5.320825576782227, 2.7235896587371826, 4.827852725982666, 5.403393268585205, 3.8855059146881104, 2.527740478515625, 3.857393264770508, 4.614030361175537, 4.950523853302002, 5.381946086883545, 4.519566059112549, 5.310620307922363, 4.7224345207214355, 5.323917388916016, 5.015167236328125, 2.5919604301452637, 4.171149253845215, 1.3670167922973633, 2.4838192462921143, 3.9411122798919678, 1.4407297372817993, 5.048005104064941, 5.125758171081543, 1.6108734607696533, 5.335157871246338, 4.889325141906738, 2.6290183067321777, 2.627180814743042, 5.244604587554932, 2.766187906265259, 4.4301910400390625, 5.393606662750244, 4.552706718444824, 4.11802339553833, 5.0324835777282715, 4.856046199798584, 5.015389442443848, 2.3867712020874023, 5.264078617095947, 5.023038387298584, 4.2878828048706055, 4.538599967956543, 3.2428901195526123, 5.291632652282715, 5.10789155960083, 5.113372802734375, 5.357789039611816, 5.141751766204834, 5.097296237945557, 1.4831926822662354, 5.21624755859375, 5.271385192871094, 3.001060724258423, 4.421950340270996, 1.364070177078247, 3.4037435054779053, 5.187147617340088, 4.439995765686035, 2.895970582962036, 4.046724319458008, 3.370621681213379, 4.658884048461914, 3.3430776596069336, 1.8018856048583984, 5.303411960601807, 5.3453145027160645, 5.343169212341309, 3.5881404876708984, 2.7631454467773438, 1.2289808988571167, 2.0268261432647705, 4.197690010070801, 4.314071178436279, 2.8061914443969727, 2.965489149093628, 5.375113010406494, 5.395437717437744, 3.343857765197754, 3.914419651031494, 5.218472480773926, 4.895402431488037, 5.312217712402344, 1.5388635396957397, 5.163853168487549, 5.13452672958374, 5.206559181213379, 4.637889385223389, 5.398382186889648, 4.745560169219971, 3.5364623069763184, 3.3111226558685303, 1.3260104656219482, 5.328719615936279, 4.073203086853027, 3.4145665168762207, 5.034913063049316, 5.319918155670166, 3.645639419555664, 2.3835527896881104, 4.330226898193359, 4.909546375274658, 5.19176721572876, 4.283442497253418, 2.091348171234131, 3.8846848011016846, 4.752753734588623, 4.946136474609375, 5.259754180908203, 5.350907325744629, 3.4591476917266846, 5.272066593170166, 1.9187246561050415, 4.818881988525391, 5.028808116912842, 5.392941474914551, 4.952460765838623, 5.4021897315979, 4.938775062561035, 3.0157628059387207, 3.993980884552002, 5.3732523918151855, 4.39509391784668, 5.385948181152344, 5.001519203186035, 4.378181457519531, 3.184386730194092, 4.212514877319336, 2.3287391662597656, 2.8758842945098877, 3.95088529586792, 5.350872993469238, 2.9430134296417236, 2.977463960647583, 3.809105396270752, 5.2519636154174805, 5.051117420196533, 2.644571304321289, 5.211279392242432, 5.403630256652832, 4.932921886444092, 5.352900981903076, 2.9936983585357666, 5.37803316116333, 5.127949237823486, 2.619687080383301, 3.2882583141326904, 4.831230163574219, 5.06487512588501, 1.9525666236877441, 5.1271281242370605, 4.588481426239014, 3.7768404483795166, 1.8227475881576538, 4.322610855102539, 5.163501262664795, 3.931046962738037, 5.084317684173584, 4.479262351989746, 4.359803676605225, 2.992249011993408, 4.527164459228516, 2.6667776107788086, 3.690131902694702, 5.302351474761963, 4.921392917633057, 4.915501117706299, 4.865785598754883, 1.4143474102020264, 4.162363529205322, 4.954147815704346, 1.1620187759399414, 5.261800765991211, 2.0640807151794434, 4.944499492645264, 4.334758758544922, 3.9714317321777344, 2.833217144012451, 5.330234050750732, 4.2859697341918945, 1.4028265476226807, 5.1061015129089355, 4.7581892013549805, 3.5046157836914062, 3.224574327468872, 5.038495063781738, 1.6222928762435913, 5.1357550621032715, 5.379945755004883, 3.4844348430633545, 5.070201873779297, 3.185652256011963, 4.342789173126221, 5.388024806976318, 5.362512111663818, 3.7914628982543945, 4.8231587409973145, 5.119032382965088, 1.3673158884048462, 1.6338832378387451, 1.3175857067108154, 4.976621150970459, 1.2447454929351807, 4.9064154624938965, 5.273509502410889, 3.3194518089294434, 3.6306631565093994, 3.3837242126464844, 3.6526811122894287, 5.322587490081787, 4.630716323852539, 5.3054304122924805, 5.226261138916016, 5.392847061157227, 3.6676950454711914, 5.391515254974365, 4.252748966217041, 4.796249866485596, 4.821643352508545, 4.983366012573242, 5.297170639038086, 1.9239752292633057, 3.617694616317749, 4.410114288330078, 5.249473571777344, 5.259919166564941, 5.357086658477783, 5.151798725128174, 5.359863758087158, 5.3440260887146, 2.9077818393707275, 5.100809097290039, 2.0463573932647705, 4.8314528465271, 5.266264915466309, 1.971481442451477, 4.886276721954346, 5.2528157234191895, 1.4440268278121948, 5.151228427886963, 5.065296649932861, 5.155801296234131, 3.6923437118530273, 5.3285908699035645, 5.382333278656006, 3.5377421379089355, 3.7620396614074707, 2.362766742706299, 1.4028505086898804, 2.595932960510254, 5.255432605743408, 4.515220642089844, 4.868166446685791, 4.318103313446045, 2.0692298412323, 5.397199630737305, 1.2835988998413086, 3.8266336917877197, 5.3521552085876465, 4.164471626281738, 5.3081583976745605, 3.9553916454315186, 4.507165908813477, 1.2577905654907227, 3.35345196723938, 5.306295871734619, 2.979790210723877, 5.40330171585083, 4.396079063415527, 5.255893230438232, 5.299061298370361, 2.097105026245117, 1.7010891437530518, 3.793839454650879, 3.482694387435913, 2.442840099334717, 4.925375461578369, 5.113584041595459, 5.397682189941406, 4.44623327255249, 5.132075786590576, 4.846710681915283, 5.127076625823975, 5.297171115875244, 1.6280016899108887, 5.351907253265381, 5.085385799407959, 5.241124629974365, 5.09042501449585, 1.9286521673202515, 4.966063022613525, 2.88082218170166, 5.307979106903076, 5.091334819793701, 4.4878106117248535, 5.34401273727417, 2.283607244491577, 4.708876609802246, 1.194018006324768, 5.338843822479248, 4.112776279449463, 4.633981704711914, 5.2344279289245605, 4.764017105102539, 5.007896423339844, 4.3914594650268555, 3.1142704486846924, 5.204112529754639, 3.379904270172119, 2.800833225250244, 4.944271564483643, 4.069097995758057, 2.3640851974487305, 4.967379570007324, 2.5524485111236572, 5.175295352935791, 4.940981388092041, 4.655523300170898, 5.2462029457092285, 4.1588592529296875, 5.370914936065674, 3.7821102142333984, 4.78117036819458, 4.556911468505859, 4.766972064971924, 3.7750566005706787, 4.701727390289307, 4.195679664611816, 3.697263717651367, 3.5072968006134033, 3.6623265743255615, 4.606661319732666, 4.797765254974365, 3.665200710296631, 5.357639312744141, 2.7684688568115234, 1.3445782661437988, 5.279201030731201, 4.619537830352783, 3.789571762084961, 5.3729166984558105, 5.033494472503662, 1.7443547248840332, 4.985105037689209, 5.320773601531982, 2.3632194995880127, 2.643956184387207, 4.725892066955566, 5.220761775970459, 5.118799686431885, 3.3508050441741943, 2.508664131164551, 5.36067008972168, 3.7193665504455566, 5.35438346862793, 5.158139705657959]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzDLjwm9mlhkXfjOzzPx/ReaVekr4YJkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    # Model parameters\n",
    "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5     # Generator complexity\n",
    "    g_output_size = 1     # Size of generated output vector\n",
    "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "    d_hidden_size = 10    # Discriminator complexity\n",
    "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "    minibatch_size = d_input_size\n",
    "\n",
    "    d_learning_rate = 1e-3\n",
    "    g_learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "\n",
    "    num_epochs = 5000\n",
    "    print_interval = 100\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "    discriminator_activation_function = torch.sigmoid\n",
    "    generator_activation_function = torch.tanh\n",
    "\n",
    "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "    gi_sampler = get_generator_input_sampler()\n",
    "    G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size,\n",
    "                      f=discriminator_activation_function)\n",
    "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size))\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "\n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "\n",
    "    if matplotlib_is_available:\n",
    "        print(\"Plotting the generated distribution...\")\n",
    "        values = extract(g_fake_data)\n",
    "        print(\" Values: %s\" % (str(values)))\n",
    "        plt.hist(values, bins=50)\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Histogram of Generated Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Generative adversarial networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
