{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S7-1EFP4WwfM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "hMuV4Ax6Nq-j",
    "outputId": "25e836f9-c336-4f05-d96a-20b9b84487e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-53e66900b598>:11: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# MNIST tensorflow example\n",
    "\n",
    "'''\n",
    "A Convolutional Network implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/) '''\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHRIcRthOMiD"
   },
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-u4vI61OdSY"
   },
   "outputs": [],
   "source": [
    "# Create some custom functions for CNN layers\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkrHYC5YOl15"
   },
   "outputs": [],
   "source": [
    "# Creating model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkcUPZNLOxNF"
   },
   "outputs": [],
   "source": [
    "# Storing layers weight & bias for the model\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nQK6AYrlO6og",
    "outputId": "6f143755-7e80-48b8-cb39-1d36170e5e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 128, Minibatch Loss= 78814.664062, Training Accuracy= 0.17188\n",
      "Iter 1408, Minibatch Loss= 23862.623047, Training Accuracy= 0.30469\n",
      "Iter 2688, Minibatch Loss= 11507.935547, Training Accuracy= 0.57031\n",
      "Iter 3968, Minibatch Loss= 4938.315918, Training Accuracy= 0.73438\n",
      "Iter 5248, Minibatch Loss= 4444.632324, Training Accuracy= 0.76562\n",
      "Iter 6528, Minibatch Loss= 2696.487305, Training Accuracy= 0.82812\n",
      "Iter 7808, Minibatch Loss= 3894.045410, Training Accuracy= 0.85156\n",
      "Iter 9088, Minibatch Loss= 4697.814453, Training Accuracy= 0.78906\n",
      "Iter 10368, Minibatch Loss= 1304.470093, Training Accuracy= 0.92188\n",
      "Iter 11648, Minibatch Loss= 1621.230225, Training Accuracy= 0.89062\n",
      "Iter 12928, Minibatch Loss= 3063.492676, Training Accuracy= 0.85156\n",
      "Iter 14208, Minibatch Loss= 1768.517334, Training Accuracy= 0.87500\n",
      "Iter 15488, Minibatch Loss= 1200.990112, Training Accuracy= 0.92969\n",
      "Iter 16768, Minibatch Loss= 2214.009521, Training Accuracy= 0.83594\n",
      "Iter 18048, Minibatch Loss= 1165.280273, Training Accuracy= 0.91406\n",
      "Iter 19328, Minibatch Loss= 1541.178345, Training Accuracy= 0.90625\n",
      "Iter 20608, Minibatch Loss= 769.133057, Training Accuracy= 0.92969\n",
      "Iter 21888, Minibatch Loss= 3116.637695, Training Accuracy= 0.89844\n",
      "Iter 23168, Minibatch Loss= 1743.520020, Training Accuracy= 0.90625\n",
      "Iter 24448, Minibatch Loss= 2414.432861, Training Accuracy= 0.89062\n",
      "Iter 25728, Minibatch Loss= 582.600769, Training Accuracy= 0.96875\n",
      "Iter 27008, Minibatch Loss= 1475.858398, Training Accuracy= 0.91406\n",
      "Iter 28288, Minibatch Loss= 772.758972, Training Accuracy= 0.92969\n",
      "Iter 29568, Minibatch Loss= 606.067993, Training Accuracy= 0.92969\n",
      "Iter 30848, Minibatch Loss= 539.434448, Training Accuracy= 0.96875\n",
      "Iter 32128, Minibatch Loss= 1366.016113, Training Accuracy= 0.91406\n",
      "Iter 33408, Minibatch Loss= 1292.547119, Training Accuracy= 0.96094\n",
      "Iter 34688, Minibatch Loss= 761.920898, Training Accuracy= 0.93750\n",
      "Iter 35968, Minibatch Loss= 493.591064, Training Accuracy= 0.96875\n",
      "Iter 37248, Minibatch Loss= 1573.254150, Training Accuracy= 0.92969\n",
      "Iter 38528, Minibatch Loss= 990.358765, Training Accuracy= 0.92188\n",
      "Iter 39808, Minibatch Loss= 880.931213, Training Accuracy= 0.95312\n",
      "Iter 41088, Minibatch Loss= 839.776001, Training Accuracy= 0.94531\n",
      "Iter 42368, Minibatch Loss= 1586.935547, Training Accuracy= 0.92969\n",
      "Iter 43648, Minibatch Loss= 645.226562, Training Accuracy= 0.92969\n",
      "Iter 44928, Minibatch Loss= 871.307007, Training Accuracy= 0.92969\n",
      "Iter 46208, Minibatch Loss= 484.841858, Training Accuracy= 0.96094\n",
      "Iter 47488, Minibatch Loss= 281.324768, Training Accuracy= 0.96875\n",
      "Iter 48768, Minibatch Loss= 105.470398, Training Accuracy= 0.97656\n",
      "Iter 50048, Minibatch Loss= 1647.008423, Training Accuracy= 0.92969\n",
      "Iter 51328, Minibatch Loss= 1452.522583, Training Accuracy= 0.92188\n",
      "Iter 52608, Minibatch Loss= 137.859665, Training Accuracy= 0.96875\n",
      "Iter 53888, Minibatch Loss= 104.061951, Training Accuracy= 0.97656\n",
      "Iter 55168, Minibatch Loss= 1387.302368, Training Accuracy= 0.90625\n",
      "Iter 56448, Minibatch Loss= 969.323914, Training Accuracy= 0.95312\n",
      "Iter 57728, Minibatch Loss= 800.858582, Training Accuracy= 0.93750\n",
      "Iter 59008, Minibatch Loss= 237.127396, Training Accuracy= 0.94531\n",
      "Iter 60288, Minibatch Loss= 279.538239, Training Accuracy= 0.96094\n",
      "Iter 61568, Minibatch Loss= 354.109192, Training Accuracy= 0.96875\n",
      "Iter 62848, Minibatch Loss= 537.223206, Training Accuracy= 0.97656\n",
      "Iter 64128, Minibatch Loss= 305.403351, Training Accuracy= 0.95312\n",
      "Iter 65408, Minibatch Loss= 451.306976, Training Accuracy= 0.95312\n",
      "Iter 66688, Minibatch Loss= 1185.400146, Training Accuracy= 0.94531\n",
      "Iter 67968, Minibatch Loss= 357.655090, Training Accuracy= 0.96875\n",
      "Iter 69248, Minibatch Loss= 417.147156, Training Accuracy= 0.96094\n",
      "Iter 70528, Minibatch Loss= 99.105316, Training Accuracy= 0.99219\n",
      "Iter 71808, Minibatch Loss= 207.043060, Training Accuracy= 0.96875\n",
      "Iter 73088, Minibatch Loss= 925.498657, Training Accuracy= 0.94531\n",
      "Iter 74368, Minibatch Loss= 765.651794, Training Accuracy= 0.94531\n",
      "Iter 75648, Minibatch Loss= 270.206116, Training Accuracy= 0.97656\n",
      "Iter 76928, Minibatch Loss= 401.020630, Training Accuracy= 0.94531\n",
      "Iter 78208, Minibatch Loss= 100.464615, Training Accuracy= 0.98438\n",
      "Iter 79488, Minibatch Loss= 186.104919, Training Accuracy= 0.97656\n",
      "Iter 80768, Minibatch Loss= 143.998093, Training Accuracy= 0.97656\n",
      "Iter 82048, Minibatch Loss= 395.222351, Training Accuracy= 0.96094\n",
      "Iter 83328, Minibatch Loss= 202.718445, Training Accuracy= 0.97656\n",
      "Iter 84608, Minibatch Loss= 176.457336, Training Accuracy= 0.97656\n",
      "Iter 85888, Minibatch Loss= 171.120331, Training Accuracy= 0.97656\n",
      "Iter 87168, Minibatch Loss= 479.039673, Training Accuracy= 0.96094\n",
      "Iter 88448, Minibatch Loss= 239.505585, Training Accuracy= 0.97656\n",
      "Iter 89728, Minibatch Loss= 250.394516, Training Accuracy= 0.96875\n",
      "Iter 91008, Minibatch Loss= 545.447021, Training Accuracy= 0.93750\n",
      "Iter 92288, Minibatch Loss= 698.380310, Training Accuracy= 0.93750\n",
      "Iter 93568, Minibatch Loss= 487.922424, Training Accuracy= 0.96094\n",
      "Iter 94848, Minibatch Loss= 474.637634, Training Accuracy= 0.95312\n",
      "Iter 96128, Minibatch Loss= 65.724319, Training Accuracy= 0.98438\n",
      "Iter 97408, Minibatch Loss= 323.519836, Training Accuracy= 0.95312\n",
      "Iter 98688, Minibatch Loss= 355.136353, Training Accuracy= 0.93750\n",
      "Iter 99968, Minibatch Loss= 311.139709, Training Accuracy= 0.95312\n",
      "Iter 101248, Minibatch Loss= 234.819168, Training Accuracy= 0.96094\n",
      "Iter 102528, Minibatch Loss= 249.170074, Training Accuracy= 0.96875\n",
      "Iter 103808, Minibatch Loss= 98.817879, Training Accuracy= 0.97656\n",
      "Iter 105088, Minibatch Loss= 340.278076, Training Accuracy= 0.94531\n",
      "Iter 106368, Minibatch Loss= 638.443359, Training Accuracy= 0.94531\n",
      "Iter 107648, Minibatch Loss= 311.440857, Training Accuracy= 0.96875\n",
      "Iter 108928, Minibatch Loss= 447.987488, Training Accuracy= 0.96875\n",
      "Iter 110208, Minibatch Loss= 140.522842, Training Accuracy= 0.96875\n",
      "Iter 111488, Minibatch Loss= 298.624634, Training Accuracy= 0.96875\n",
      "Iter 112768, Minibatch Loss= 122.061157, Training Accuracy= 0.97656\n",
      "Iter 114048, Minibatch Loss= 382.823242, Training Accuracy= 0.95312\n",
      "Iter 115328, Minibatch Loss= 783.745605, Training Accuracy= 0.92188\n",
      "Iter 116608, Minibatch Loss= 120.323074, Training Accuracy= 0.98438\n",
      "Iter 117888, Minibatch Loss= 664.354980, Training Accuracy= 0.94531\n",
      "Iter 119168, Minibatch Loss= 131.306961, Training Accuracy= 0.96875\n",
      "Iter 120448, Minibatch Loss= 195.802246, Training Accuracy= 0.97656\n",
      "Iter 121728, Minibatch Loss= 406.540070, Training Accuracy= 0.95312\n",
      "Iter 123008, Minibatch Loss= 194.782852, Training Accuracy= 0.97656\n",
      "Iter 124288, Minibatch Loss= 78.365524, Training Accuracy= 0.97656\n",
      "Iter 125568, Minibatch Loss= 374.557495, Training Accuracy= 0.96094\n",
      "Iter 126848, Minibatch Loss= 644.215698, Training Accuracy= 0.93750\n",
      "Iter 128128, Minibatch Loss= 302.651001, Training Accuracy= 0.96094\n",
      "Iter 129408, Minibatch Loss= 375.322937, Training Accuracy= 0.94531\n",
      "Iter 130688, Minibatch Loss= 389.047607, Training Accuracy= 0.95312\n",
      "Iter 131968, Minibatch Loss= 236.705948, Training Accuracy= 0.96875\n",
      "Iter 133248, Minibatch Loss= 138.962402, Training Accuracy= 0.96875\n",
      "Iter 134528, Minibatch Loss= 294.798431, Training Accuracy= 0.96875\n",
      "Iter 135808, Minibatch Loss= 300.064423, Training Accuracy= 0.96875\n",
      "Iter 137088, Minibatch Loss= 26.783798, Training Accuracy= 0.98438\n",
      "Iter 138368, Minibatch Loss= 233.325226, Training Accuracy= 0.97656\n",
      "Iter 139648, Minibatch Loss= 123.165833, Training Accuracy= 0.99219\n",
      "Iter 140928, Minibatch Loss= 119.492081, Training Accuracy= 0.97656\n",
      "Iter 142208, Minibatch Loss= 161.794342, Training Accuracy= 0.99219\n",
      "Iter 143488, Minibatch Loss= 68.395645, Training Accuracy= 0.98438\n",
      "Iter 144768, Minibatch Loss= 43.046906, Training Accuracy= 0.99219\n",
      "Iter 146048, Minibatch Loss= 256.801910, Training Accuracy= 0.97656\n",
      "Iter 147328, Minibatch Loss= 115.567215, Training Accuracy= 0.96875\n",
      "Iter 148608, Minibatch Loss= 144.003799, Training Accuracy= 0.97656\n",
      "Iter 149888, Minibatch Loss= 32.974052, Training Accuracy= 0.97656\n",
      "Iter 151168, Minibatch Loss= 302.897705, Training Accuracy= 0.96875\n",
      "Iter 152448, Minibatch Loss= 138.618378, Training Accuracy= 0.96875\n",
      "Iter 153728, Minibatch Loss= 229.418533, Training Accuracy= 0.97656\n",
      "Iter 155008, Minibatch Loss= 264.373108, Training Accuracy= 0.96875\n",
      "Iter 156288, Minibatch Loss= 49.510468, Training Accuracy= 0.97656\n",
      "Iter 157568, Minibatch Loss= 66.870560, Training Accuracy= 0.99219\n",
      "Iter 158848, Minibatch Loss= 303.231476, Training Accuracy= 0.96094\n",
      "Iter 160128, Minibatch Loss= 58.090942, Training Accuracy= 0.97656\n",
      "Iter 161408, Minibatch Loss= 348.294006, Training Accuracy= 0.96094\n",
      "Iter 162688, Minibatch Loss= 27.939911, Training Accuracy= 0.99219\n",
      "Iter 163968, Minibatch Loss= 66.521133, Training Accuracy= 0.98438\n",
      "Iter 165248, Minibatch Loss= 3.355324, Training Accuracy= 0.99219\n",
      "Iter 166528, Minibatch Loss= 216.704346, Training Accuracy= 0.95312\n",
      "Iter 167808, Minibatch Loss= 252.021332, Training Accuracy= 0.94531\n",
      "Iter 169088, Minibatch Loss= 175.301025, Training Accuracy= 0.95312\n",
      "Iter 170368, Minibatch Loss= 51.278015, Training Accuracy= 0.99219\n",
      "Iter 171648, Minibatch Loss= 26.906418, Training Accuracy= 0.98438\n",
      "Iter 172928, Minibatch Loss= 339.726074, Training Accuracy= 0.96094\n",
      "Iter 174208, Minibatch Loss= 2.062836, Training Accuracy= 0.99219\n",
      "Iter 175488, Minibatch Loss= 26.447174, Training Accuracy= 0.98438\n",
      "Iter 176768, Minibatch Loss= 73.939507, Training Accuracy= 0.97656\n",
      "Iter 178048, Minibatch Loss= 19.940262, Training Accuracy= 0.97656\n",
      "Iter 179328, Minibatch Loss= 341.432007, Training Accuracy= 0.96094\n",
      "Iter 180608, Minibatch Loss= 299.277161, Training Accuracy= 0.96094\n",
      "Iter 181888, Minibatch Loss= 197.660065, Training Accuracy= 0.96875\n",
      "Iter 183168, Minibatch Loss= 259.752808, Training Accuracy= 0.96094\n",
      "Iter 184448, Minibatch Loss= 65.174477, Training Accuracy= 0.97656\n",
      "Iter 185728, Minibatch Loss= 151.156647, Training Accuracy= 0.96875\n",
      "Iter 187008, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 188288, Minibatch Loss= 138.818405, Training Accuracy= 0.96875\n",
      "Iter 189568, Minibatch Loss= 33.387802, Training Accuracy= 0.98438\n",
      "Iter 190848, Minibatch Loss= 23.372787, Training Accuracy= 0.98438\n",
      "Iter 192128, Minibatch Loss= 237.825623, Training Accuracy= 0.96875\n",
      "Iter 193408, Minibatch Loss= 277.453369, Training Accuracy= 0.96875\n",
      "Iter 194688, Minibatch Loss= 50.439758, Training Accuracy= 0.97656\n",
      "Iter 195968, Minibatch Loss= 23.582802, Training Accuracy= 0.99219\n",
      "Iter 197248, Minibatch Loss= 52.618141, Training Accuracy= 0.98438\n",
      "Iter 198528, Minibatch Loss= 66.654465, Training Accuracy= 0.98438\n",
      "Iter 199808, Minibatch Loss= 157.635941, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.98828125\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print (\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print (\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
